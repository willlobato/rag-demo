# ğŸš€ Tutorial Completo: RAG com LangChain, ChromaDB e Ollama

> **Sistema Educacional RAG Demo**
> 
> ğŸ“š **[Ãndice da DocumentaÃ§Ã£o](../organization/INDICE_DOCUMENTACAO.md)** | **[Guia de NavegaÃ§Ã£o](GUIA_NAVEGACAO.md)** | **[ClassificaÃ§Ã£o de Scripts](../organization/CLASSIFICACAO_SCRIPTS.md)**

Este tutorial fornece uma base teÃ³rica sÃ³lida para o sistema educacional RAG, preparando vocÃª para usar os scripts prÃ¡ticos de forma efetiva.

---

## ğŸ“š **NAVEGAÃ‡ÃƒO RÃPIDA**

### **ğŸ“– Fundamentos TeÃ³ricos**
1. **[O que Ã© RAG?](#o-que-Ã©-rag)** - Conceitos fundamentais
2. **[Arquitetura do Sistema](#arquitetura-do-sistema)** - Design tÃ©cnico
3. **[Chunks e Overlaps](#fundamentaÃ§Ã£o-chunks-e-overlaps)** - **ESSENCIAL: Como textos sÃ£o processados**
4. **[Guardrails em Sistemas RAG](#guardrails-em-sistemas-rag)** - **ğŸ›¡ï¸ PROTEÃ‡Ã•ES: SeguranÃ§a e qualidade**
5. **[Componentes TÃ©cnicos](#componentes-tÃ©cnicos)** - Tecnologias utilizadas

### **ğŸ› ï¸ ImplementaÃ§Ã£o PrÃ¡tica**
4. **[ConfiguraÃ§Ã£o e InstalaÃ§Ã£o](#configuraÃ§Ã£o-e-instalaÃ§Ã£o)** - Setup inicial
5. **[Scripts BÃ¡sicos](#scripts-bÃ¡sicos)** - **[Ver Scripts NÃ­vel BÃ¡sico](CLASSIFICACAO_SCRIPTS.md#-nÃ­vel-bÃ¡sico---fundamentos-essenciais)**
6. **[Scripts AvanÃ§ados](#scripts-avanÃ§ados)** - **[Ver Scripts NÃ­vel AvanÃ§ado](CLASSIFICACAO_SCRIPTS.md#-nÃ­vel-avanÃ§ado---pesquisa-e-experimentaÃ§Ã£o)**

### **ğŸ“Š AnÃ¡lise e OtimizaÃ§Ã£o**
7. **[AnÃ¡lise e AvaliaÃ§Ã£o](#anÃ¡lise-e-avaliaÃ§Ã£o)** - **[Ver Exemplos PrÃ¡ticos](EXEMPLOS_USO_SCRIPTS.md)**
8. **[Casos de Uso PrÃ¡ticos](#casos-de-uso-prÃ¡ticos)** - **[Ver DocumentaÃ§Ã£o AvanÃ§ada](../reference/DOCUMENTACAO_SCRIPTS_AVANCADOS.md)**
9. **[OtimizaÃ§Ã£o e Troubleshooting](#otimizaÃ§Ã£o-e-troubleshooting)** - **[Ver Guia de NavegaÃ§Ã£o](GUIA_NAVEGACAO.md#navegaÃ§Ã£o-por-problema-especÃ­fico)**

### **ğŸš€ PrÃ³ximos Passos**
10. **[ProgressÃ£o de Aprendizagem](#prÃ³ximos-passos)** - **[Ver Fluxo Completo](INDICE_DOCUMENTACAO.md#-fluxo-de-aprendizagem-recomendado)**

---

## ğŸ¤– O que Ã© RAG?

**RAG (Retrieval-Augmented Generation)** Ã© uma tÃ©cnica de IA que combina:

### ğŸ” **RecuperaÃ§Ã£o (Retrieval)**
- Busca informaÃ§Ãµes relevantes em uma base de conhecimento
- Usa **similaridade semÃ¢ntica** (nÃ£o apenas palavras-chave)
- Trabalha com **embeddings vetoriais**

### âœ¨ **GeraÃ§Ã£o (Generation)**
- Um LLM (Large Language Model) gera a resposta
- Usa o **contexto recuperado** como base
- Produz respostas **fundamentadas e precisas**

### ğŸ¯ **Por que RAG Ã© Importante?**

| Problema Tradicional | SoluÃ§Ã£o RAG |
|---|---|
| LLMs tÃªm conhecimento limitado | Acesso a dados atualizados |
| InformaÃ§Ãµes podem estar desatualizadas | Base de conhecimento dinÃ¢mica |
| Respostas podem ser inventadas ("hallucination") | Respostas baseadas em fontes reais |
| NÃ£o cita fontes | TransparÃªncia e rastreabilidade |

### ğŸ”„ **Fluxo RAG Simplificado**

```
Pergunta â†’ Busca Vetorial â†’ Contexto â†’ LLM â†’ Resposta + Fontes
```

---

## ğŸ—ï¸ Arquitetura do Sistema

### ğŸ“Š **Diagrama do Fluxo**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Documentos    â”‚â”€â”€â”€â–¶â”‚   Processamento  â”‚â”€â”€â”€â–¶â”‚   ChromaDB      â”‚
â”‚  (TXT/PDF/MD)   â”‚    â”‚   + Chunking     â”‚    â”‚  (Vetores)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–²                        â”‚
                                â”‚                        â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     TikToken     â”‚    â”‚   RecuperaÃ§Ã£o   â”‚
                        â”‚  (TokenizaÃ§Ã£o)   â”‚    â”‚   SemÃ¢ntica     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   Resposta      â”‚â—€â”€â”€â”€â”‚      LLM         â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   + Fontes      â”‚    â”‚   (Llama3)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ **Componentes Principais**

1. **IngestÃ£o**: Carrega e processa documentos
2. **Chunking**: Divide documentos em pedaÃ§os menores
3. **Embeddings**: Converte texto em vetores numÃ©ricos
4. **Armazenamento**: Salva vetores no ChromaDB
5. **RecuperaÃ§Ã£o**: Busca chunks relevantes
6. **GeraÃ§Ã£o**: LLM produz resposta final

---

## ğŸ”ª **FUNDAMENTAÃ‡ÃƒO: CHUNKS E OVERLAPS**

### ğŸ¯ **O que sÃ£o Chunks?**

**Chunks** sÃ£o fragmentos de texto de tamanho limitado criados pela divisÃ£o de documentos maiores. Ã‰ o processo mais crÃ­tico em sistemas RAG, pois determina:

- **Granularidade**: QuÃ£o especÃ­fica Ã© a informaÃ§Ã£o recuperada
- **Contexto**: Quantidade de informaÃ§Ã£o disponÃ­vel por busca
- **Performance**: Velocidade de busca e geraÃ§Ã£o de embeddings
- **Qualidade**: PrecisÃ£o das respostas geradas

### ğŸ“ **Por que Precisamos de Chunks?**

**1. LimitaÃ§Ãµes TÃ©cnicas:**
```python
# LimitaÃ§Ãµes tÃ­picas de modelos
MAX_TOKENS_EMBEDDING = 8192    # nomic-embed-text
MAX_TOKENS_LLM = 4096          # contexto tÃ­pico llama3
MAX_CHUNK_SIZE = 500           # nosso padrÃ£o
```

**2. LimitaÃ§Ãµes Cognitivas:**
- LLMs tÃªm dificuldade com textos muito longos
- InformaÃ§Ã£o relevante pode "se perder" em meio a muito contexto
- Embeddings de textos grandes sÃ£o menos precisos

**3. EficiÃªncia Computacional:**
- Busca vetorial Ã© mais rÃ¡pida com chunks menores
- Menos dados transferidos pela rede
- Processamento paralelo mais eficiente

### ğŸ§© **Como Funciona o Chunking?**

**EstratÃ©gia HierÃ¡rquica (RecursiveCharacterTextSplitter):**

```python
# Separadores em ordem de prioridade
separators = [
    "\n\n",    # 1Âº: ParÃ¡grafos (preserva estrutura semÃ¢ntica)
    "\n",      # 2Âº: Linhas (mantÃ©m unidade textual)  
    " ",       # 3Âº: Palavras (preserva tokens)
    ""         # 4Âº: Caracteres (Ãºltimo recurso)
]

# Processo inteligente
1. Tenta dividir por parÃ¡grafo
2. Se ainda muito grande â†’ divide por linha
3. Se ainda muito grande â†’ divide por palavra
4. Se ainda muito grande â†’ divide por caractere
```

**Exemplo PrÃ¡tico:**
```
Documento Original (1500 chars):
"A inteligÃªncia artificial (IA) Ã© uma tecnologia...
[parÃ¡grafo 1: 600 chars]

Machine Learning Ã© um subcampo da IA que permite...
[parÃ¡grafo 2: 500 chars]

Deep Learning, por sua vez, utiliza redes neurais...
[parÃ¡grafo 3: 400 chars]"

Resultado do Chunking (CHUNK_SIZE=500):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CHUNK 1 (500 chars)                â”‚
â”‚ "A inteligÃªncia artificial (IA)...  â”‚
â”‚ [parÃ¡grafo 1 completo]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CHUNK 2 (500 chars)                â”‚  
â”‚ "Machine Learning Ã© um subcampo...  â”‚
â”‚ [parÃ¡grafo 2 + inÃ­cio do 3]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CHUNK 3 (320 chars)                â”‚
â”‚ "Deep Learning, por sua vez...      â”‚  
â”‚ [resto do parÃ¡grafo 3]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”— **O que sÃ£o Overlaps?**

**Overlap** Ã© a sobreposiÃ§Ã£o intencional entre chunks consecutivos. Em nosso sistema: **CHUNK_OVERLAP = 80 caracteres (~16% do chunk)**.

**VisualizaÃ§Ã£o do Overlap:**
```
CHUNK 1: "...conceitos de machine learning sÃ£o fundamentais para..."
                                        â†• OVERLAP (80 chars)
CHUNK 2: "...sÃ£o fundamentais para compreender deep learning..."
```

### ğŸ¯ **Por que Overlaps sÃ£o NecessÃ¡rios?**

**1. PreservaÃ§Ã£o de Contexto:**
```
âŒ SEM OVERLAP:
Chunk 1: "A tÃ©cnica de gradient descent Ã© utilizada para otimizar"
Chunk 2: "funÃ§Ãµes de custo em redes neurais."
âŒ InformaÃ§Ã£o fragmentada!

âœ… COM OVERLAP:
Chunk 1: "A tÃ©cnica de gradient descent Ã© utilizada para otimizar"
Chunk 2: "otimizar funÃ§Ãµes de custo em redes neurais profundas."
âœ… Contexto preservado!
```

**2. Evitar Quebra de Conceitos:**
- SentenÃ§as nÃ£o ficam cortadas pela metade
- Conceitos relacionados permanecem juntos
- ReferÃªncias pronominais mantÃªm sentido

**3. RedundÃ¢ncia EstratÃ©gica:**
- MÃºltiplas oportunidades de recuperar informaÃ§Ã£o importante
- Maior chance de encontrar contexto relevante
- CompensaÃ§Ã£o para imprecisÃµes na busca vetorial

### ğŸ—„ï¸ **Como o Banco Vetorial Opera com Chunks?**

**1. Processo de Armazenamento:**
```python
# Para cada chunk individual
chunk_text = "Machine learning Ã© um subcampo..."

# 1. GeraÃ§Ã£o de Embedding
embedding = embedding_model.embed(chunk_text)
# Resultado: vetor de 768 dimensÃµes [0.123, -0.456, 0.789, ...]

# 2. Armazenamento no ChromaDB
vector_store.add(
    documents=[chunk_text],
    embeddings=[embedding], 
    metadatas=[{"source": "ai_tutorial.txt", "chunk_id": 1}],
    ids=["chunk_1"]
)
```

**2. Estrutura de Dados Resultante:**
```
ChromaDB Collection "demo-rag":
â”œâ”€â”€ chunk_1: [embedding_768d] + metadata + texto
â”œâ”€â”€ chunk_2: [embedding_768d] + metadata + texto  
â”œâ”€â”€ chunk_3: [embedding_768d] + metadata + texto
â””â”€â”€ ...
```

**3. Processo de Busca:**
```python
# Consulta: "Como funciona machine learning?"

# 1. Embedding da consulta
query_embedding = embedding_model.embed("Como funciona machine learning?")

# 2. Busca por similaridade cosseno
results = vector_store.similarity_search_with_score(
    query_embedding, 
    k=4  # TOP-4 chunks mais similares
)

# 3. Resultado: chunks rankeados por relevÃ¢ncia
# Score 0.92: "Machine learning Ã© um subcampo..."
# Score 0.87: "Algoritmos de ML aprendem padrÃµes..."  
# Score 0.82: "Tipos de aprendizado incluem..."
# Score 0.78: "AplicaÃ§Ãµes prÃ¡ticas de ML..."
```

### ğŸ§® **Como Funcionam os Embeddings neste Processo?**

**1. Embeddings de Chunks Individuais:**
```python
# Cada chunk vira um ponto no espaÃ§o 768-dimensional
chunk_1 = "IA Ã© uma tecnologia revolucionÃ¡ria..."
embedding_1 = [0.12, -0.34, 0.56, ..., 0.78]  # 768 nÃºmeros

chunk_2 = "Machine learning utiliza algoritmos..."  
embedding_2 = [0.15, -0.31, 0.52, ..., 0.81]  # 768 nÃºmeros

# Chunks similares ficam prÃ³ximos no espaÃ§o vetorial
similarity = cosine_similarity(embedding_1, embedding_2)  # 0.87
```

**2. Vantagens de Embeddings por Chunk:**
- **PrecisÃ£o**: Cada embedding representa um conceito especÃ­fico
- **EficiÃªncia**: Busca mais rÃ¡pida em vetores menores
- **Granularidade**: Pode recuperar informaÃ§Ã£o muito especÃ­fica

**3. MatemÃ¡tica da Busca Vetorial:**
```python
# Similaridade cosseno entre query e chunk
def cosine_similarity(vec_a, vec_b):
    dot_product = sum(a * b for a, b in zip(vec_a, vec_b))
    norm_a = sqrt(sum(a * a for a in vec_a))
    norm_b = sqrt(sum(b * b for b in vec_b))
    return dot_product / (norm_a * norm_b)

# Valores prÃ³ximos de 1.0 = muito similares
# Valores prÃ³ximos de 0.0 = pouco similares  
# Valores negativos = opostos semanticamente
```

### âš–ï¸ **Desafios e Trade-offs de Chunks/Overlaps**

**1. Tamanho dos Chunks:**

| Tamanho | Vantagens | Desvantagens | Quando Usar |
|---------|-----------|--------------|-------------|
| **Pequeno (200-300)** | â€¢ Alta precisÃ£o<br>â€¢ Busca rÃ¡pida<br>â€¢ Menos ruÃ­do | â€¢ Pouco contexto<br>â€¢ Pode fragmentar conceitos<br>â€¢ Mais chunks a gerenciar | â€¢ Bases de dados tÃ©cnicas<br>â€¢ FAQ estruturado<br>â€¢ Respostas curtas |
| **MÃ©dio (500-800)** | â€¢ Bom balance<br>â€¢ Contexto suficiente<br>â€¢ Performance adequada | â€¢ Trade-off moderado | â€¢ **PADRÃƒO RECOMENDADO**<br>â€¢ DocumentaÃ§Ã£o geral<br>â€¢ Maioria dos casos |
| **Grande (1000-1500)** | â€¢ Muito contexto<br>â€¢ Preserva estrutura<br>â€¢ Menos fragmentaÃ§Ã£o | â€¢ Busca mais lenta<br>â€¢ Embeddings menos precisos<br>â€¢ Pode incluir ruÃ­do | â€¢ Textos literÃ¡rios<br>â€¢ AnÃ¡lises complexas<br>â€¢ Contexto muito importante |

**2. Overlaps:**

| Overlap | Vantagens | Desvantagens | CenÃ¡rio Ideal |
|---------|-----------|--------------|---------------|
| **0% (sem overlap)** | â€¢ Sem redundÃ¢ncia<br>â€¢ Menos armazenamento<br>â€¢ Menos processamento | â€¢ âŒ Perde contexto<br>â€¢ âŒ Fragmenta conceitos<br>â€¢ âŒ ReferÃªncias quebradas | â€¢ **NÃƒO RECOMENDADO**<br>â€¢ Apenas em casos de espaÃ§o limitado |
| **10-20% (conservador)** | â€¢ Preserva contexto bÃ¡sico<br>â€¢ Pouca redundÃ¢ncia<br>â€¢ Eficiente | â€¢ Pode ainda fragmentar<br>â€¢ Contexto limitado | â€¢ Documentos bem estruturados<br>â€¢ Textos com seÃ§Ãµes claras |
| **20-30% (padrÃ£o)** | â€¢ âœ… **BOM BALANCE**<br>â€¢ âœ… Preserva contexto<br>â€¢ âœ… Evita fragmentaÃ§Ã£o | â€¢ RedundÃ¢ncia moderada<br>â€¢ Mais armazenamento | â€¢ **RECOMENDADO**<br>â€¢ Nosso padrÃ£o: 16% |
| **40%+ (alto)** | â€¢ MÃ¡xima preservaÃ§Ã£o<br>â€¢ RedundÃ¢ncia alta<br>â€¢ Contexto garantido | â€¢ âŒ Muito armazenamento<br>â€¢ âŒ Busca mais lenta<br>â€¢ âŒ InformaÃ§Ã£o duplicada | â€¢ Textos muito complexos<br>â€¢ Contexto crÃ­tico |

### ğŸ¯ **Como Decidir ParÃ¢metros de Chunking?**

**AnÃ¡lise do Tipo de ConteÃºdo:**
```python
# DOCUMENTAÃ‡ÃƒO TÃ‰CNICA
CHUNK_SIZE = 600        # Contexto suficiente para explicaÃ§Ãµes
CHUNK_OVERLAP = 100     # 16% - preserva referÃªncias tÃ©cnicas

# FAQ / RESPOSTAS CURTAS  
CHUNK_SIZE = 300        # Respostas diretas
CHUNK_OVERLAP = 50      # 16% - mÃ­nimo necessÃ¡rio

# TEXTOS ACADÃŠMICOS
CHUNK_SIZE = 800        # Argumentos complexos precisam de contexto
CHUNK_OVERLAP = 150     # 18% - preserva estrutura argumentativa

# CÃ“DIGO FONTE (se aplicÃ¡vel)
CHUNK_SIZE = 1000       # FunÃ§Ãµes/classes completas
CHUNK_OVERLAP = 200     # 20% - preserva dependÃªncias
```

**MÃ©tricas para Otimizar:**
```python
# 1. Execute anÃ¡lise de chunks
python scripts/analyze_chunks.py --full

# 2. Verifique mÃ©tricas de qualidade  
python scripts/evaluate_rag.py

# 3. Teste diferentes configuraÃ§Ãµes
export CHUNK_SIZE=800
export CHUNK_OVERLAP=150
python scripts/run_ingest.py

# 4. Compare resultados
python scripts/run_query.py "pergunta teste"
```

### ğŸ”¬ **AnÃ¡lise AvanÃ§ada de Chunks**

**Script de AnÃ¡lise Detalhada:**
```bash
# Ver estatÃ­sticas completas de chunking
python scripts/analyze_chunks.py --full

# AnÃ¡lises que vocÃª verÃ¡:
# â€¢ DistribuiÃ§Ã£o de tamanhos
# â€¢ Overlaps efetivos encontrados  
# â€¢ Chunks por documento
# â€¢ ConteÃºdo exato dos overlaps
# â€¢ IdentificaÃ§Ã£o de problemas
```

**MÃ©tricas Importantes:**
- **Tamanho mÃ©dio real** vs configurado
- **Percentual de overlap efetivo**
- **Chunks "Ã³rfÃ£os"** (muito pequenos)
- **DistribuiÃ§Ã£o por documento**
- **Qualidade da preservaÃ§Ã£o de estrutura**

### ğŸš€ **OtimizaÃ§Ã£o PrÃ¡tica**

**1. ConfiguraÃ§Ã£o Recomendada (nosso padrÃ£o):**
```python
CHUNK_SIZE = 500        # Balance contexto/precisÃ£o
CHUNK_OVERLAP = 80      # 16% - preserva contexto
RETRIEVAL_K = 4         # TOP-4 chunks mais relevantes
```

**2. Para Experimentar:**
```bash
# Teste chunks maiores para mais contexto
export CHUNK_SIZE=800
export CHUNK_OVERLAP=120

# Teste mais overlaps para mÃ¡xima preservaÃ§Ã£o  
export CHUNK_OVERLAP=150

# Teste recuperar mais chunks
export RETRIEVAL_K=6
```

**3. Monitoramento ContÃ­nuo:**
- Execute `analyze_chunks.py` apÃ³s mudanÃ§as
- Teste com perguntas reais do seu domÃ­nio
- Compare qualidade das respostas
- Monitore tempo de resposta

---

## ğŸ›¡ï¸ **GUARDRAILS EM SISTEMAS RAG**

### ğŸ¯ **O que sÃ£o Guardrails?**

**Guardrails** sÃ£o mecanismos de controle e validaÃ§Ã£o que garantem que sistemas RAG produzam respostas **seguras, precisas e baseadas exclusivamente no contexto** recuperado, evitando alucinaÃ§Ãµes e respostas inventadas.

### ğŸ—ï¸ **Arquitetura de Guardrails (4 Camadas)**

```
INPUT â†’ [ğŸ” Input Guards] â†’ RETRIEVAL â†’ [âš–ï¸ Relevance Guards] â†’ 
GENERATION â†’ [ğŸ“ Prompt Guards] â†’ OUTPUT â†’ [âœ… Output Guards] â†’ RESPOSTA
```

**1. INPUT GUARDRAILS (PrÃ©-processamento):**
- ValidaÃ§Ã£o de queries maliciosas (injection attacks)
- SanitizaÃ§Ã£o e normalizaÃ§Ã£o de entrada
- Filtro de queries muito curtas/longas

**2. RETRIEVAL GUARDRAILS (RecuperaÃ§Ã£o):**
- **Threshold de similaridade rigoroso** - filtra contexto irrelevante
- Curto-circuito quando nÃ£o hÃ¡ contexto adequado
- ValidaÃ§Ã£o de qualidade dos chunks recuperados

**3. PROMPT GUARDRAILS (GeraÃ§Ã£o):**
- **Templates rigorosos** que limitam escopo do LLM
- InstruÃ§Ãµes explÃ­citas: "responda APENAS com base no contexto"
- Formato de resposta padronizado

**4. OUTPUT GUARDRAILS (PÃ³s-processamento):**
- ValidaÃ§Ã£o de fidelidade ao contexto
- DetecÃ§Ã£o de alucinaÃ§Ãµes
- VerificaÃ§Ã£o de citaÃ§Ã£o de fontes

### âš–ï¸ **Threshold de Similaridade - O CoraÃ§Ã£o dos Guardrails**

**O threshold determina quÃ£o "similar" um chunk deve ser para ser considerado relevante:**

```python
# ChromaDB usa distÃ¢ncia (menor = mais similar)
THRESHOLD_STRICT = 0.25      # Apenas chunks muito relevantes
THRESHOLD_BALANCED = 0.35    # Balance entre precisÃ£o e cobertura  
THRESHOLD_PERMISSIVE = 0.50  # Aceita contexto menos relevante
```

**Exemplo prÃ¡tico:**
```bash
# Query: "Como funciona cache distribuÃ­do?"
# Chunk 1: "Redis Ã© usado como cache distribuÃ­do..." (score: 0.15) âœ… ACEITO
# Chunk 2: "Implementamos microserviÃ§os..."        (score: 0.40) âŒ REJEITADO
# Chunk 3: "Cache distribuÃ­do com Infinispan..."   (score: 0.18) âœ… ACEITO

# Resultado: Apenas chunks 1 e 3 sÃ£o enviados ao LLM
```

### ğŸ”§ **ImplementaÃ§Ã£o PrÃ¡tica**

**1. Sistema RAG com Guardrails Completos:**
```bash
# Script principal com todas as proteÃ§Ãµes
python scripts/rag_with_guardrails.py "Qual Ã© a latÃªncia das APIs?"

# Diferentes nÃ­veis de rigor
python scripts/rag_with_guardrails.py "Como funciona Kubernetes?" strict strict
python scripts/rag_with_guardrails.py "Explique microserviÃ§os" balanced balanced
```

**2. OtimizaÃ§Ã£o de Threshold:**
```bash
# AnÃ¡lise automÃ¡tica para encontrar threshold Ã³timo
python scripts/threshold_optimizer.py

# Resultado: recomendaÃ§Ã£o baseada em anÃ¡lise estatÃ­stica
```

### ğŸ“Š **Tipos de Prompt Templates**

**1. STRICT Template (MÃ¡xima SeguranÃ§a):**
```
VocÃª Ã© um assistente que responde EXCLUSIVAMENTE com base no contexto fornecido.

REGRAS OBRIGATÃ“RIAS:
1. Use APENAS informaÃ§Ãµes presentes no CONTEXTO
2. Se nÃ£o estiver no contexto: "âŒ NÃ£o encontrei informaÃ§Ãµes relevantes"
3. NUNCA invente, deduza ou use conhecimento externo
4. Sempre cite a fonte: (Fonte: arquivo.txt)
```

**2. BALANCED Template (Flexibilidade Limitada):**
```
Priorize SEMPRE as informaÃ§Ãµes do CONTEXTO fornecido.
Use conhecimento geral apenas para esclarecimentos bÃ¡sicos.
Indique claramente quando uma informaÃ§Ã£o vem do contexto vs conhecimento geral.
```

### âš¡ **Resultados dos Guardrails**

**Sem Guardrails:**
```
Query: "Como funciona inteligÃªncia artificial?"
Resposta: "A inteligÃªncia artificial Ã© um campo amplo que inclui machine learning, 
deep learning, processamento de linguagem natural..." [ALUCINAÃ‡ÃƒO - info nÃ£o estÃ¡ no contexto]
```

**Com Guardrails:**
```
Query: "Como funciona inteligÃªncia artificial?"  
Resposta: "âŒ NÃ£o encontrei informaÃ§Ãµes relevantes no contexto disponÃ­vel."
[CORRETO - info realmente nÃ£o estÃ¡ no sistema_completo.txt]
```

**Contexto Encontrado:**
```
Query: "Qual Ã© a latÃªncia das APIs?"
Resposta: "âœ… Com base no contexto fornecido: A latÃªncia mÃ©dia das APIs Ã© de 150ms 
em 99% dos casos. (Fonte: sistema_completo.txt)"
[CORRETO - info extraÃ­da exatamente do contexto]
```

### ğŸ¯ **ConfiguraÃ§Ã£o de Threshold por Caso de Uso**

| Tipo de Sistema | Threshold | Justificativa |
|------------------|-----------|---------------|
| **Sistema CrÃ­tico** (medicina, financeiro) | 0.20-0.25 | Zero tolerÃ¢ncia a informaÃ§Ã£o incorreta |
| **DocumentaÃ§Ã£o TÃ©cnica** (nosso exemplo) | 0.30-0.35 | Balance entre precisÃ£o e cobertura |
| **FAQ/Suporte** | 0.40-0.50 | Cobertura mais importante que precisÃ£o absoluta |
| **Busca ExploratÃ³ria** | 0.50-0.60 | Descoberta de informaÃ§Ã£o relacionada |

### ğŸ”¬ **AnÃ¡lise de Qualidade dos Guardrails**

**MÃ©tricas Importantes:**
```bash
# Executar anÃ¡lise completa
python scripts/rag_with_guardrails.py --test

# MÃ©tricas reportadas:
# â€¢ Taxa de Sucesso: % de queries respondidas com contexto
# â€¢ Taxa de RejeiÃ§Ã£o: % de queries rejeitadas por baixa relevÃ¢ncia  
# â€¢ Taxa de ProteÃ§Ã£o: % de queries maliciosas bloqueadas
# â€¢ Fidelidade MÃ©dia: % de resposta baseada no contexto
```

**InterpretaÃ§Ã£o:**
- **Alta Taxa de RejeiÃ§Ã£o** = Threshold muito rigoroso
- **Baixa Fidelidade** = Template muito permissivo  
- **Muitas Respostas GenÃ©ricas** = Threshold muito permissivo

### ğŸš¨ **DetecÃ§Ã£o de Ataques de Injection**

**PadrÃµes Bloqueados Automaticamente:**
```bash
# Tentativas de manipulaÃ§Ã£o do prompt
"ignore previous instructions"
"forget everything and act as"
"system: you are now"

# Resultado: Query rejeitada antes de chegar ao LLM
```

### ğŸ›ï¸ **ConfiguraÃ§Ã£o AvanÃ§ada**

**VariÃ¡veis de Ambiente para Guardrails:**
```bash
# Threshold de similaridade
export SIMILARITY_THRESHOLD=0.30

# Modo de template (strict/balanced)
export TEMPLATE_MODE=strict

# NÃºmero mÃ­nimo de chunks necessÃ¡rios
export MIN_CHUNKS_REQUIRED=2

# Ativar logs detalhados de guardrails
export GUARDRAILS_VERBOSE=1
```

### ğŸ“ˆ **OtimizaÃ§Ã£o ContÃ­nua**

**1. AnÃ¡lise de Threshold:**
```bash
# Encontrar threshold Ã³timo para seus dados
python scripts/threshold_optimizer.py

# Resultado: recomendaÃ§Ã£o estatÃ­stica baseada em seus documentos
```

**2. Monitoramento de Qualidade:**
```bash
# Logs de decisÃµes de guardrail
tail -f guardrails.log

# MÃ©tricas de performance
python scripts/evaluate_rag.py --guardrails
```

### ğŸ¯ **Casos de Uso AvanÃ§ados**

**1. Threshold Adaptativo:**
```python
# Threshold baseado na complexidade da query
if len(query.split()) > 10:
    threshold = 0.40  # Queries complexas precisam de mais contexto
else:
    threshold = 0.30  # Queries simples podem ser mais rigorosas
```

**2. ValidaÃ§Ã£o SemÃ¢ntica:**
```python
# Verificar se resposta "faz sentido" semanticamente
similarity_score = cosine_similarity(query_embedding, response_embedding)
if similarity_score < 0.6:
    return "âŒ Resposta gerada nÃ£o parece relacionada Ã  pergunta"
```

**3. Guardrails EspecÃ­ficos por DomÃ­nio:**
```python
# Regras especÃ­ficas para documentaÃ§Ã£o tÃ©cnica
if "performance" in query.lower():
    required_keywords = ["latÃªncia", "tempo", "velocidade", "ms", "segundos"]
    if not any(keyword in response.lower() for keyword in required_keywords):
        flag_as_potentially_hallucinated()
```

### ğŸ† **Boas PrÃ¡ticas para Guardrails**

**1. Comece Rigoroso:**
- Use threshold baixo (0.25-0.30) inicialmente
- Aumente gradualmente baseado em anÃ¡lise empÃ­rica

**2. Monitore Continuamente:**
- Log todas as decisÃµes de guardrail
- Analise queries rejeitadas para detectar falsos negativos
- Revise periodicamente threshold baseado em feedback

**3. Teste Adversarial:**
- Teste com queries maliciosas intencionalmente
- Valide que queries fora do domÃ­nio sÃ£o rejeitadas
- Verifique que respostas inventadas sÃ£o detectadas

**4. Balance PrecisÃ£o vs Usabilidade:**
- Guardrails muito rigorosos frustram usuÃ¡rios
- Guardrails muito permissivos comprometem qualidade
- Encontre o sweet spot para seu caso de uso

### ğŸš€ **ImplementaÃ§Ã£o em ProduÃ§Ã£o**

**Arquitetura Recomendada:**
```
API Request â†’ Rate Limiting â†’ Input Validation â†’ 
RAG with Guardrails â†’ Output Validation â†’ Response + Metadata
```

**Monitoramento Essencial:**
- Taxa de queries rejeitadas por guardrail
- Tempo mÃ©dio de processamento por threshold
- Feedback de usuÃ¡rios sobre qualidade das respostas
- DetecÃ§Ã£o de tentativas de bypass

**Os Guardrails transformam um sistema RAG experimental em um sistema confiÃ¡vel para produÃ§Ã£o!** ğŸ›¡ï¸âœ¨

---

## ğŸ› ï¸ Componentes TÃ©cnicos

### ğŸ¦œ **LangChain Framework**

**O que Ã©:** Framework para desenvolvimento de aplicaÃ§Ãµes com LLMs

**Por que usar:**
- **AbstraÃ§Ã£o**: Simplifica operaÃ§Ãµes complexas
- **IntegraÃ§Ãµes**: Conecta diferentes ferramentas facilmente
- **PadrÃµes**: Implementa melhores prÃ¡ticas
- **Flexibilidade**: Suporta mÃºltiplos modelos e provedores

**Principais mÃ³dulos usados:**
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter  # Chunking
from langchain_chroma import Chroma                                  # Vector Store
from langchain_ollama import OllamaEmbeddings, ChatOllama          # Modelos
from langchain.prompts import ChatPromptTemplate                    # Prompts
from langchain.schema.runnable import RunnablePassthrough           # Chains
```

### ğŸ—„ï¸ **ChromaDB - Vector Database**

**O que Ã©:** Banco de dados especializado em vetores

**CaracterÃ­sticas:**
- **PersistÃªncia**: Dados salvos em disco
- **Similaridade**: Busca por cosine similarity
- **Metadados**: Armazena informaÃ§Ãµes adicionais
- **Performance**: Otimizado para embeddings

**Como funciona:**
```python
# Criar/conectar
vect = Chroma(
    collection_name="demo-rag",
    persist_directory="db",
    embedding_function=embeddings
)

# Buscar similares
results = vect.similarity_search_with_score("minha query", k=5)
```

### ğŸ”¢ **TikToken - TokenizaÃ§Ã£o**

**O que Ã©:** Biblioteca para contar tokens de modelos OpenAI

**Por que importante:**
- **Limites**: Modelos tÃªm limite de tokens
- **Custos**: APIs cobram por token
- **Chunking**: Garante chunks dentro do limite
- **OtimizaÃ§Ã£o**: Controla tamanho de contexto

**Uso prÃ¡tico:**
```python
import tiktoken

# Contar tokens
encoding = tiktoken.get_encoding("cl100k_base")
tokens = encoding.encode("seu texto aqui")
print(f"Tokens: {len(tokens)}")
```

### ğŸ¤– **Ollama - Modelos Locais**

**O que Ã©:** Plataforma para rodar LLMs localmente

**Vantagens:**
- **Privacidade**: Dados nÃ£o saem da mÃ¡quina
- **Gratuito**: Sem custos de API
- **Offline**: Funciona sem internet
- **Performance**: Otimizado para hardware local

**Modelos usados:**
- **llama3**: GeraÃ§Ã£o de texto (8B parÃ¢metros)
- **nomic-embed-text**: Embeddings (768 dimensÃµes)

---

## ğŸ¯ Scripts BÃ¡sicos

### 1. **run_ingest.py** - IndexaÃ§Ã£o de Documentos

**O que faz:**
```bash
python scripts/run_ingest.py
```

**Processo:**
1. Carrega documentos da pasta `data/`
2. Divide em chunks (500 caracteres, overlap 80)
3. Gera embeddings com `nomic-embed-text`
4. Salva no ChromaDB

**Quando usar:**
- Primeira vez que configura o sistema
- Adicionar novos documentos
- Resetar Ã­ndice: `RESET_CHROMA=1 python scripts/run_ingest.py`

### 2. **run_query.py** - Consultas RAG

**O que faz:**
```bash
python scripts/run_query.py "Como otimizar performance?"
```

**Processo:**
1. Gera embedding da pergunta
2. Busca 4 chunks mais similares
3. Monta prompt com contexto
4. LLM gera resposta
5. Retorna resposta + fontes

**Quando usar:**
- Fazer perguntas sobre seus documentos
- Testar qualidade das respostas
- DemonstraÃ§Ãµes do sistema

### 3. **list_docs.py** - Explorar Ãndice

**O que faz:**
```bash
python scripts/list_docs.py
```

**Mostra:**
- Total de chunks indexados
- ConteÃºdo de cada chunk
- Metadados (fonte, etc.)

**Quando usar:**
- Verificar o que foi indexado
- Debug de problemas de ingestÃ£o
- Explorar dados disponÃ­veis

### 4. **search_docs.py** - Busca SemÃ¢ntica

**O que faz:**
```bash
python scripts/search_docs.py "machine learning" 5
```

**Processo:**
- Busca semÃ¢ntica SEM usar LLM
- Retorna chunks + scores de similaridade
- Mais rÃ¡pido que consulta RAG completa

**Quando usar:**
- Testar qualidade da recuperaÃ§Ã£o
- AnÃ¡lise de relevÃ¢ncia
- Debug de embeddings

### 5. **show_vectors.py** - AnÃ¡lise de Vetores

**O que faz:**
```bash
python scripts/show_vectors.py "tecnologia" true
```

**Mostra:**
- Embedding da query (768 dimensÃµes)
- Vetores dos documentos
- Valores numÃ©ricos reais
- Normas L2 e estatÃ­sticas

**Quando usar:**
- Entender como funcionam embeddings
- Debug de similaridade
- AnÃ¡lise matemÃ¡tica profunda

### 6. **analyze_chunks.py** - ğŸ”¥ **ANÃLISE ESSENCIAL DE CHUNKING**

**O que faz:**
```bash
python scripts/analyze_chunks.py --full
```

**AnÃ¡lises CrÃ­ticas:**
- âœ… **EstatÃ­sticas de tamanho** dos chunks (mÃ©dia, min, max)
- âœ… **Overlaps entre chunks consecutivos** - detecta e mostra sobreposiÃ§Ãµes
- âœ… **DistribuiÃ§Ã£o por documento** - como cada arquivo foi dividido
- âœ… **Qualidade do chunking** - identifica problemas de fragmentaÃ§Ã£o
- âœ… **ConteÃºdo exato dos overlaps** - mostra texto sobreposto

**Quando usar:**
- ğŸ¯ **SEMPRE** apÃ³s configurar ou mudar parÃ¢metros de chunking
- ğŸ”§ Otimizar CHUNK_SIZE e CHUNK_OVERLAP  
- ğŸ› Debug de problemas de sobreposiÃ§Ã£o
- ğŸ“Š Entender como documentos foram processados
- âš™ï¸ **Antes de otimizar performance** - veja a seÃ§Ã£o [Chunks e Overlaps](#fundamentaÃ§Ã£o-chunks-e-overlaps)

### 7. **list_raw.py** - Listagem Simples

**O que faz:**
```bash
python scripts/list_raw.py
```

**CaracterÃ­sticas:**
- Interface mais simples
- Mostra texto completo + embeddings
- Sem parÃ¢metros necessÃ¡rios

**Quando usar:**
- VerificaÃ§Ã£o rÃ¡pida do Ã­ndice
- Primeira exploraÃ§Ã£o dos dados
- Interface simples para iniciantes

---

## ğŸ”¬ Scripts AvanÃ§ados

### 1. **rag_with_guardrails.py** - ğŸ›¡ï¸ **RAG COM PROTEÃ‡Ã•ES COMPLETAS**

**O que faz:**
```bash
# RAG bÃ¡sico com guardrails
python scripts/rag_with_guardrails.py "Qual Ã© a latÃªncia das APIs?"

# Configurar rigor dos filtros
python scripts/rag_with_guardrails.py "Como funciona Kubernetes?" strict strict
python scripts/rag_with_guardrails.py "Explique microserviÃ§os" permissive balanced

# Teste automÃ¡tico com mÃºltiplas queries
python scripts/rag_with_guardrails.py --test
```

**Para que serve:**
- ğŸ›¡ï¸ **ProteÃ§Ã£o contra alucinaÃ§Ãµes** - forÃ§a aderÃªncia ao contexto
- âš–ï¸ **Filtro de relevÃ¢ncia** - threshold de similaridade rigoroso
- ğŸ”’ **ValidaÃ§Ã£o de entrada** - detecta tentativas de injection
- âœ… **ValidaÃ§Ã£o de saÃ­da** - verifica fidelidade e citaÃ§Ã£o de fontes
- ğŸ“Š **MÃ©tricas de qualidade** - avalia efetividade dos guardrails

**Quando usar:**
- **SEMPRE** em sistemas de produÃ§Ã£o
- Quando precisar de respostas 100% baseadas no contexto
- Para sistemas crÃ­ticos (medicina, finanÃ§as, legal)
- AnÃ¡lise de seguranÃ§a e robustez

### 2. **threshold_optimizer.py** - ğŸ“Š **OTIMIZAÃ‡ÃƒO AUTOMÃTICA DE THRESHOLD**

**O que faz:**
```bash
# AnÃ¡lise completa e recomendaÃ§Ã£o de threshold Ã³timo
python scripts/threshold_optimizer.py
```

**Para que serve:**
- ğŸ“ˆ **AnÃ¡lise estatÃ­stica** de distribuiÃ§Ã£o de scores de similaridade
- ğŸ¯ **RecomendaÃ§Ã£o automÃ¡tica** de threshold baseada em dados
- âš–ï¸ **Trade-off analysis** entre precisÃ£o e cobertura
- ğŸ“Š **VisualizaÃ§Ãµes** de performance por threshold
- ğŸ† **Threshold Ã³timo** para seu dataset especÃ­fico

**Quando usar:**
- **Antes de configurar um sistema RAG** para encontrar parÃ¢metros ideais
- Quando mudar o tipo de documentos/conteÃºdo
- Para otimizaÃ§Ã£o de performance
- AnÃ¡lise cientÃ­fica de qualidade de embeddings

### 3. **evaluate_rag.py** - ğŸ”¬ **AVALIAÃ‡ÃƒO DE QUALIDADE**

**Para que serve:**
- Medir qualidade objetiva das respostas
- Comparar diferentes configuraÃ§Ãµes
- Benchmark do sistema
- MÃ©tricas cientÃ­ficas

### 2. **analyze_similarity.py** - AnÃ¡lise de Similaridade

**Para que serve:**
- Heatmap de similaridade entre chunks
- Detectar duplicatas
- Clustering de documentos
- VisualizaÃ§Ã£o do espaÃ§o vetorial

### 3. **experiment.py** - ExperimentaÃ§Ã£o

**Para que serve:**
- A/B testing de configuraÃ§Ãµes
- Comparar modelos de embedding
- Testar diferentes chunk sizes
- Batch testing

### 4. **analyze_retrieval.py** - AnÃ¡lise de RecuperaÃ§Ã£o

**Para que serve:**
- MÃ©tricas de recuperaÃ§Ã£o (Recall@K, Precision@K)
- Qualidade dos chunks recuperados
- Debug de queries problemÃ¡ticas
- AnÃ¡lise de ranking

### 5. **advanced_metrics.py** - MÃ©tricas AvanÃ§adas

**Para que serve:**
- EstatÃ­sticas detalhadas dos embeddings
- DistribuiÃ§Ãµes de distÃ¢ncia
- AnÃ¡lise de clusters
- Insights matemÃ¡ticos

---

## ğŸ“Š AnÃ¡lise e AvaliaÃ§Ã£o

### MÃ©tricas de Qualidade RAG

**1. MÃ©tricas de RecuperaÃ§Ã£o:**
- **Recall@K**: % de documentos relevantes recuperados
- **Precision@K**: % de documentos recuperados que sÃ£o relevantes
- **MRR**: Mean Reciprocal Rank
- **NDCG**: Normalized Discounted Cumulative Gain

**2. MÃ©tricas de GeraÃ§Ã£o:**
- **BLEU**: Similaridade com resposta de referÃªncia
- **ROUGE**: Overlap de n-gramas
- **Faithfulness**: Fidelidade ao contexto
- **Answer Relevance**: RelevÃ¢ncia da resposta

**3. MÃ©tricas de Sistema:**
- **LatÃªncia**: Tempo de resposta
- **Throughput**: Queries por segundo
- **ConsistÃªncia**: Variabilidade das respostas

### Ferramentas de AvaliaÃ§Ã£o

**RAGAS Framework:**
```python
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy

# Avaliar dataset
results = evaluate(
    dataset=eval_dataset,
    metrics=[faithfulness, answer_relevancy]
)
```

---

## ğŸ’¡ Casos de Uso PrÃ¡ticos

### 1. **Sistema de DocumentaÃ§Ã£o Interna**
- Documentos tÃ©cnicos da empresa
- Manuais e procedimentos
- Base de conhecimento de suporte

### 2. **Assistente de Pesquisa**
- Papers cientÃ­ficos
- Literatura acadÃªmica
- RelatÃ³rios de pesquisa

### 3. **Chatbot de Atendimento**
- FAQ empresarial
- PolÃ­ticas e regulamentos
- Guias de produto

### 4. **Sistema de AnÃ¡lise Legal**
- Documentos jurÃ­dicos
- Precedentes legais
- Contratos e regulamentaÃ§Ãµes

### 5. **Assistente MÃ©dico**
- Literatura mÃ©dica
- Protocolos de tratamento
- Bases de dados clÃ­nicas

---

## âš™ï¸ OtimizaÃ§Ã£o e Troubleshooting

### OtimizaÃ§Ã£o de Performance

**1. Chunking Strategy (ğŸ“– [Ver seÃ§Ã£o detalhada](#fundamentaÃ§Ã£o-chunks-e-overlaps)):**
```python
# Teste diferentes tamanhos - consulte guia completo acima
CHUNK_SIZES = [250, 500, 1000, 1500]
OVERLAPS = [50, 100, 200]

# Analise resultados com:
python scripts/analyze_chunks.py --full

# Avalie qual combinaÃ§Ã£o funciona melhor para SEU caso
for size in CHUNK_SIZES:
    for overlap in OVERLAPS:
        export CHUNK_SIZE=$size
        export CHUNK_OVERLAP=$overlap
        python scripts/run_ingest.py
        python scripts/run_query.py "sua pergunta teste"
```

**2. Embedding Models:**
- `nomic-embed-text`: 768 dim, rÃ¡pido
- `all-MiniLM-L6-v2`: 384 dim, mais rÃ¡pido
- `text-embedding-ada-002`: 1536 dim, mais preciso

**3. Retrieval Tuning:**
```python
# NÃºmero de chunks recuperados
RETRIEVAL_K = [3, 5, 7, 10]

# Limiar de similaridade
SIMILARITY_THRESHOLD = 0.7
```

### Problemas Comuns

**1. Respostas Irrelevantes:**
- Verificar qualidade dos embeddings
- Ajustar chunk size
- Melhorar prompt template
- Filtrar chunks por score

**2. Performance Lenta:**
- Usar modelo de embedding menor
- Implementar cache de embeddings
- Otimizar Ã­ndice ChromaDB
- Reduzir nÃºmero de chunks recuperados

**3. Hallucinations:**
- Ser mais especÃ­fico no prompt
- Usar temperatura menor
- Implementar validaÃ§Ã£o de resposta
- Adicionar disclaimers

---

## ğŸš€ PrÃ³ximos Passos

### ExpansÃµes TÃ©cnicas

**1. Interface Web:**
```python
# Streamlit
import streamlit as st

st.title("RAG Assistant")
query = st.text_input("Sua pergunta:")
if query:
    response = rag_system.query(query)
    st.write(response)
```

**2. API REST:**
```python
# FastAPI
from fastapi import FastAPI

app = FastAPI()

@app.post("/query")
async def query_rag(question: str):
    return {"answer": rag_system.query(question)}
```

**3. Embeddings Customizados:**
- Fine-tuning de modelos
- Domain-specific embeddings
- Multilingual embeddings

### Funcionalidades AvanÃ§adas

**1. Multi-Modal RAG:**
- Imagens + texto
- Tabelas e grÃ¡ficos
- Documentos estruturados

**2. Conversational RAG:**
- MemÃ³ria de contexto
- Follow-up questions
- Session management

**3. Hierarchical RAG:**
- MÃºltiplos nÃ­veis de chunking
- SummarizaÃ§Ã£o automÃ¡tica
- Routing inteligente

### Ferramentas de ProduÃ§Ã£o

**1. Monitoramento:**
- Logging estruturado
- MÃ©tricas de performance
- Alertas de qualidade

**2. Deployment:**
- ContainerizaÃ§Ã£o (Docker)
- OrquestraÃ§Ã£o (Kubernetes)
- Load balancing

**3. SeguranÃ§a:**
- AutenticaÃ§Ã£o e autorizaÃ§Ã£o
- Rate limiting
- Data privacy

---

## ğŸ“š Recursos de Aprendizado

### DocumentaÃ§Ã£o Oficial
- [LangChain](https://python.langchain.com/)
- [ChromaDB](https://docs.trychroma.com/)
- [Ollama](https://ollama.ai/)

### Papers Importantes
- "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" (Facebook AI)
- "Dense Passage Retrieval for Open-Domain Question Answering" (Facebook AI)
- "FiD: Fusion-in-Decoder for Open-domain Question Answering" (Facebook AI)

### Cursos e Tutoriais
- LangChain Academy
- DeepLearning.AI RAG Course
- Hugging Face NLP Course

---

## ğŸ“ ConclusÃ£o

Este tutorial cobriu:

âœ… **Conceitos fundamentais** de RAG
âœ… **Arquitetura tÃ©cnica** completa
âœ… **ImplementaÃ§Ã£o prÃ¡tica** com cÃ³digo
âœ… **Scripts de anÃ¡lise** e debugging
âœ… **MÃ©tricas de avaliaÃ§Ã£o**
âœ… **Casos de uso** reais
âœ… **OtimizaÃ§Ã£o** e troubleshooting
âœ… **PrÃ³ximos passos** para expansÃ£o

**PrÃ³ximas aÃ§Ãµes recomendadas:**
1. Execute todos os scripts bÃ¡sicos
2. Teste com seus prÃ³prios documentos
3. Implemente os scripts avanÃ§ados
4. Experimente diferentes configuraÃ§Ãµes
5. Desenvolva sua prÃ³pria aplicaÃ§Ã£o

**Lembre-se:** RAG Ã© uma tÃ©cnica poderosa que combina o melhor de dois mundos - a precisÃ£o da busca e a fluÃªncia da geraÃ§Ã£o. Com os conhecimentos deste tutorial, vocÃª tem tudo que precisa para construir sistemas RAG robustos e eficazes! ğŸš€
