# ğŸš€ Tutorial Completo: RAG com LangChain, ChromaDB e Ollama

> **Sistema Educacional RAG Demo**
> 
> ğŸ“š **[Ãndice da DocumentaÃ§Ã£o](../organization/INDICE_DOCUMENTACAO.md)** | **[Guia de NavegaÃ§Ã£o](GUIA_NAVEGACAO.md)** | **[ClassificaÃ§Ã£o de Scripts](../organization/CLASSIFICACAO_SCRIPTS.md)**

Este tutorial fornece uma base teÃ³rica sÃ³lida para o sistema educacional RAG, preparando vocÃª para usar os scripts prÃ¡ticos de forma efetiva.

---

## ğŸ“š **NAVEGAÃ‡ÃƒO RÃPIDA**

### **ğŸ“– Fundamentos TeÃ³ricos**
1. **[O que Ã© RAG?](#o-que-Ã©-rag)** - Conceitos fundamentais
2. **[Arquitetura do Sistema](#arquitetura-do-sistema)** - Design tÃ©cnico
3. **[Componentes TÃ©cnicos](#componentes-tÃ©cnicos)** - Tecnologias utilizadas

### **ğŸ› ï¸ ImplementaÃ§Ã£o PrÃ¡tica**
4. **[ConfiguraÃ§Ã£o e InstalaÃ§Ã£o](#configuraÃ§Ã£o-e-instalaÃ§Ã£o)** - Setup inicial
5. **[Scripts BÃ¡sicos](#scripts-bÃ¡sicos)** - **[Ver Scripts NÃ­vel BÃ¡sico](CLASSIFICACAO_SCRIPTS.md#-nÃ­vel-bÃ¡sico---fundamentos-essenciais)**
6. **[Scripts AvanÃ§ados](#scripts-avanÃ§ados)** - **[Ver Scripts NÃ­vel AvanÃ§ado](CLASSIFICACAO_SCRIPTS.md#-nÃ­vel-avanÃ§ado---pesquisa-e-experimentaÃ§Ã£o)**

### **ğŸ“Š AnÃ¡lise e OtimizaÃ§Ã£o**
7. **[AnÃ¡lise e AvaliaÃ§Ã£o](#anÃ¡lise-e-avaliaÃ§Ã£o)** - **[Ver Exemplos PrÃ¡ticos](EXEMPLOS_USO_SCRIPTS.md)**
8. **[Casos de Uso PrÃ¡ticos](#casos-de-uso-prÃ¡ticos)** - **[Ver DocumentaÃ§Ã£o AvanÃ§ada](../reference/DOCUMENTACAO_SCRIPTS_AVANCADOS.md)**
9. **[OtimizaÃ§Ã£o e Troubleshooting](#otimizaÃ§Ã£o-e-troubleshooting)** - **[Ver Guia de NavegaÃ§Ã£o](GUIA_NAVEGACAO.md#navegaÃ§Ã£o-por-problema-especÃ­fico)**

### **ğŸš€ PrÃ³ximos Passos**
10. **[ProgressÃ£o de Aprendizagem](#prÃ³ximos-passos)** - **[Ver Fluxo Completo](INDICE_DOCUMENTACAO.md#-fluxo-de-aprendizagem-recomendado)**

---

## ğŸ¤– O que Ã© RAG?

**RAG (Retrieval-Augmented Generation)** Ã© uma tÃ©cnica de IA que combina:

### ğŸ” **RecuperaÃ§Ã£o (Retrieval)**
- Busca informaÃ§Ãµes relevantes em uma base de conhecimento
- Usa **similaridade semÃ¢ntica** (nÃ£o apenas palavras-chave)
- Trabalha com **embeddings vetoriais**

### âœ¨ **GeraÃ§Ã£o (Generation)**
- Um LLM (Large Language Model) gera a resposta
- Usa o **contexto recuperado** como base
- Produz respostas **fundamentadas e precisas**

### ğŸ¯ **Por que RAG Ã© Importante?**

| Problema Tradicional | SoluÃ§Ã£o RAG |
|---|---|
| LLMs tÃªm conhecimento limitado | Acesso a dados atualizados |
| InformaÃ§Ãµes podem estar desatualizadas | Base de conhecimento dinÃ¢mica |
| Respostas podem ser inventadas ("hallucination") | Respostas baseadas em fontes reais |
| NÃ£o cita fontes | TransparÃªncia e rastreabilidade |

### ğŸ”„ **Fluxo RAG Simplificado**

```
Pergunta â†’ Busca Vetorial â†’ Contexto â†’ LLM â†’ Resposta + Fontes
```

---

## ğŸ—ï¸ Arquitetura do Sistema

### ğŸ“Š **Diagrama do Fluxo**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Documentos    â”‚â”€â”€â”€â–¶â”‚   Processamento  â”‚â”€â”€â”€â–¶â”‚   ChromaDB      â”‚
â”‚  (TXT/PDF/MD)   â”‚    â”‚   + Chunking     â”‚    â”‚  (Vetores)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–²                        â”‚
                                â”‚                        â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     TikToken     â”‚    â”‚   RecuperaÃ§Ã£o   â”‚
                        â”‚  (TokenizaÃ§Ã£o)   â”‚    â”‚   SemÃ¢ntica     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   Resposta      â”‚â—€â”€â”€â”€â”‚      LLM         â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   + Fontes      â”‚    â”‚   (Llama3)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ **Componentes Principais**

1. **IngestÃ£o**: Carrega e processa documentos
2. **Chunking**: Divide documentos em pedaÃ§os menores
3. **Embeddings**: Converte texto em vetores numÃ©ricos
4. **Armazenamento**: Salva vetores no ChromaDB
5. **RecuperaÃ§Ã£o**: Busca chunks relevantes
6. **GeraÃ§Ã£o**: LLM produz resposta final

---

## ğŸ› ï¸ Componentes TÃ©cnicos

### ğŸ¦œ **LangChain Framework**

**O que Ã©:** Framework para desenvolvimento de aplicaÃ§Ãµes com LLMs

**Por que usar:**
- **AbstraÃ§Ã£o**: Simplifica operaÃ§Ãµes complexas
- **IntegraÃ§Ãµes**: Conecta diferentes ferramentas facilmente
- **PadrÃµes**: Implementa melhores prÃ¡ticas
- **Flexibilidade**: Suporta mÃºltiplos modelos e provedores

**Principais mÃ³dulos usados:**
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter  # Chunking
from langchain_chroma import Chroma                                  # Vector Store
from langchain_ollama import OllamaEmbeddings, ChatOllama          # Modelos
from langchain.prompts import ChatPromptTemplate                    # Prompts
from langchain.schema.runnable import RunnablePassthrough           # Chains
```

### ğŸ—„ï¸ **ChromaDB - Vector Database**

**O que Ã©:** Banco de dados especializado em vetores

**CaracterÃ­sticas:**
- **PersistÃªncia**: Dados salvos em disco
- **Similaridade**: Busca por cosine similarity
- **Metadados**: Armazena informaÃ§Ãµes adicionais
- **Performance**: Otimizado para embeddings

**Como funciona:**
```python
# Criar/conectar
vect = Chroma(
    collection_name="demo-rag",
    persist_directory="db",
    embedding_function=embeddings
)

# Buscar similares
results = vect.similarity_search_with_score("minha query", k=5)
```

### ğŸ”¢ **TikToken - TokenizaÃ§Ã£o**

**O que Ã©:** Biblioteca para contar tokens de modelos OpenAI

**Por que importante:**
- **Limites**: Modelos tÃªm limite de tokens
- **Custos**: APIs cobram por token
- **Chunking**: Garante chunks dentro do limite
- **OtimizaÃ§Ã£o**: Controla tamanho de contexto

**Uso prÃ¡tico:**
```python
import tiktoken

# Contar tokens
encoding = tiktoken.get_encoding("cl100k_base")
tokens = encoding.encode("seu texto aqui")
print(f"Tokens: {len(tokens)}")
```

### ğŸ¤– **Ollama - Modelos Locais**

**O que Ã©:** Plataforma para rodar LLMs localmente

**Vantagens:**
- **Privacidade**: Dados nÃ£o saem da mÃ¡quina
- **Gratuito**: Sem custos de API
- **Offline**: Funciona sem internet
- **Performance**: Otimizado para hardware local

**Modelos usados:**
- **llama3**: GeraÃ§Ã£o de texto (8B parÃ¢metros)
- **nomic-embed-text**: Embeddings (768 dimensÃµes)

---

## ğŸ¯ Scripts BÃ¡sicos

### 1. **run_ingest.py** - IndexaÃ§Ã£o de Documentos

**O que faz:**
```bash
python scripts/run_ingest.py
```

**Processo:**
1. Carrega documentos da pasta `data/`
2. Divide em chunks (500 caracteres, overlap 80)
3. Gera embeddings com `nomic-embed-text`
4. Salva no ChromaDB

**Quando usar:**
- Primeira vez que configura o sistema
- Adicionar novos documentos
- Resetar Ã­ndice: `RESET_CHROMA=1 python scripts/run_ingest.py`

### 2. **run_query.py** - Consultas RAG

**O que faz:**
```bash
python scripts/run_query.py "Como otimizar performance?"
```

**Processo:**
1. Gera embedding da pergunta
2. Busca 4 chunks mais similares
3. Monta prompt com contexto
4. LLM gera resposta
5. Retorna resposta + fontes

**Quando usar:**
- Fazer perguntas sobre seus documentos
- Testar qualidade das respostas
- DemonstraÃ§Ãµes do sistema

### 3. **list_docs.py** - Explorar Ãndice

**O que faz:**
```bash
python scripts/list_docs.py
```

**Mostra:**
- Total de chunks indexados
- ConteÃºdo de cada chunk
- Metadados (fonte, etc.)

**Quando usar:**
- Verificar o que foi indexado
- Debug de problemas de ingestÃ£o
- Explorar dados disponÃ­veis

### 4. **search_docs.py** - Busca SemÃ¢ntica

**O que faz:**
```bash
python scripts/search_docs.py "machine learning" 5
```

**Processo:**
- Busca semÃ¢ntica SEM usar LLM
- Retorna chunks + scores de similaridade
- Mais rÃ¡pido que consulta RAG completa

**Quando usar:**
- Testar qualidade da recuperaÃ§Ã£o
- AnÃ¡lise de relevÃ¢ncia
- Debug de embeddings

### 5. **show_vectors.py** - AnÃ¡lise de Vetores

**O que faz:**
```bash
python scripts/show_vectors.py "tecnologia" true
```

**Mostra:**
- Embedding da query (768 dimensÃµes)
- Vetores dos documentos
- Valores numÃ©ricos reais
- Normas L2 e estatÃ­sticas

**Quando usar:**
- Entender como funcionam embeddings
- Debug de similaridade
- AnÃ¡lise matemÃ¡tica profunda

### 6. **analyze_chunks.py** - AnÃ¡lise de Chunking

**O que faz:**
```bash
python scripts/analyze_chunks.py --full
```

**AnÃ¡lises:**
- EstatÃ­sticas de tamanho dos chunks
- Overlaps entre chunks consecutivos
- DistribuiÃ§Ã£o por documento
- Qualidade do chunking

**Quando usar:**
- Otimizar parÃ¢metros de chunking
- Entender como documentos sÃ£o divididos
- Debug de problemas de sobreposiÃ§Ã£o

### 7. **list_raw.py** - Listagem Simples

**O que faz:**
```bash
python scripts/list_raw.py
```

**CaracterÃ­sticas:**
- Interface mais simples
- Mostra texto completo + embeddings
- Sem parÃ¢metros necessÃ¡rios

**Quando usar:**
- VerificaÃ§Ã£o rÃ¡pida do Ã­ndice
- Primeira exploraÃ§Ã£o dos dados
- Interface simples para iniciantes

---

## ğŸ”¬ Scripts AvanÃ§ados

Agora vou implementar scripts avanÃ§ados para aprofundar seu estudo:

### 1. **evaluate_rag.py** - AvaliaÃ§Ã£o de Qualidade

**Para que serve:**
- Medir qualidade objetiva das respostas
- Comparar diferentes configuraÃ§Ãµes
- Benchmark do sistema
- MÃ©tricas cientÃ­ficas

### 2. **analyze_similarity.py** - AnÃ¡lise de Similaridade

**Para que serve:**
- Heatmap de similaridade entre chunks
- Detectar duplicatas
- Clustering de documentos
- VisualizaÃ§Ã£o do espaÃ§o vetorial

### 3. **experiment.py** - ExperimentaÃ§Ã£o

**Para que serve:**
- A/B testing de configuraÃ§Ãµes
- Comparar modelos de embedding
- Testar diferentes chunk sizes
- Batch testing

### 4. **analyze_retrieval.py** - AnÃ¡lise de RecuperaÃ§Ã£o

**Para que serve:**
- MÃ©tricas de recuperaÃ§Ã£o (Recall@K, Precision@K)
- Qualidade dos chunks recuperados
- Debug de queries problemÃ¡ticas
- AnÃ¡lise de ranking

### 5. **advanced_metrics.py** - MÃ©tricas AvanÃ§adas

**Para que serve:**
- EstatÃ­sticas detalhadas dos embeddings
- DistribuiÃ§Ãµes de distÃ¢ncia
- AnÃ¡lise de clusters
- Insights matemÃ¡ticos

---

## ğŸ“Š AnÃ¡lise e AvaliaÃ§Ã£o

### MÃ©tricas de Qualidade RAG

**1. MÃ©tricas de RecuperaÃ§Ã£o:**
- **Recall@K**: % de documentos relevantes recuperados
- **Precision@K**: % de documentos recuperados que sÃ£o relevantes
- **MRR**: Mean Reciprocal Rank
- **NDCG**: Normalized Discounted Cumulative Gain

**2. MÃ©tricas de GeraÃ§Ã£o:**
- **BLEU**: Similaridade com resposta de referÃªncia
- **ROUGE**: Overlap de n-gramas
- **Faithfulness**: Fidelidade ao contexto
- **Answer Relevance**: RelevÃ¢ncia da resposta

**3. MÃ©tricas de Sistema:**
- **LatÃªncia**: Tempo de resposta
- **Throughput**: Queries por segundo
- **ConsistÃªncia**: Variabilidade das respostas

### Ferramentas de AvaliaÃ§Ã£o

**RAGAS Framework:**
```python
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy

# Avaliar dataset
results = evaluate(
    dataset=eval_dataset,
    metrics=[faithfulness, answer_relevancy]
)
```

---

## ğŸ’¡ Casos de Uso PrÃ¡ticos

### 1. **Sistema de DocumentaÃ§Ã£o Interna**
- Documentos tÃ©cnicos da empresa
- Manuais e procedimentos
- Base de conhecimento de suporte

### 2. **Assistente de Pesquisa**
- Papers cientÃ­ficos
- Literatura acadÃªmica
- RelatÃ³rios de pesquisa

### 3. **Chatbot de Atendimento**
- FAQ empresarial
- PolÃ­ticas e regulamentos
- Guias de produto

### 4. **Sistema de AnÃ¡lise Legal**
- Documentos jurÃ­dicos
- Precedentes legais
- Contratos e regulamentaÃ§Ãµes

### 5. **Assistente MÃ©dico**
- Literatura mÃ©dica
- Protocolos de tratamento
- Bases de dados clÃ­nicas

---

## âš™ï¸ OtimizaÃ§Ã£o e Troubleshooting

### OtimizaÃ§Ã£o de Performance

**1. Chunking Strategy:**
```python
# Teste diferentes tamanhos
CHUNK_SIZES = [250, 500, 1000, 1500]
OVERLAPS = [50, 100, 200]

# Avalie qual combinaÃ§Ã£o funciona melhor
for size in CHUNK_SIZES:
    for overlap in OVERLAPS:
        # Execute testes
        pass
```

**2. Embedding Models:**
- `nomic-embed-text`: 768 dim, rÃ¡pido
- `all-MiniLM-L6-v2`: 384 dim, mais rÃ¡pido
- `text-embedding-ada-002`: 1536 dim, mais preciso

**3. Retrieval Tuning:**
```python
# NÃºmero de chunks recuperados
RETRIEVAL_K = [3, 5, 7, 10]

# Limiar de similaridade
SIMILARITY_THRESHOLD = 0.7
```

### Problemas Comuns

**1. Respostas Irrelevantes:**
- Verificar qualidade dos embeddings
- Ajustar chunk size
- Melhorar prompt template
- Filtrar chunks por score

**2. Performance Lenta:**
- Usar modelo de embedding menor
- Implementar cache de embeddings
- Otimizar Ã­ndice ChromaDB
- Reduzir nÃºmero de chunks recuperados

**3. Hallucinations:**
- Ser mais especÃ­fico no prompt
- Usar temperatura menor
- Implementar validaÃ§Ã£o de resposta
- Adicionar disclaimers

---

## ğŸš€ PrÃ³ximos Passos

### ExpansÃµes TÃ©cnicas

**1. Interface Web:**
```python
# Streamlit
import streamlit as st

st.title("RAG Assistant")
query = st.text_input("Sua pergunta:")
if query:
    response = rag_system.query(query)
    st.write(response)
```

**2. API REST:**
```python
# FastAPI
from fastapi import FastAPI

app = FastAPI()

@app.post("/query")
async def query_rag(question: str):
    return {"answer": rag_system.query(question)}
```

**3. Embeddings Customizados:**
- Fine-tuning de modelos
- Domain-specific embeddings
- Multilingual embeddings

### Funcionalidades AvanÃ§adas

**1. Multi-Modal RAG:**
- Imagens + texto
- Tabelas e grÃ¡ficos
- Documentos estruturados

**2. Conversational RAG:**
- MemÃ³ria de contexto
- Follow-up questions
- Session management

**3. Hierarchical RAG:**
- MÃºltiplos nÃ­veis de chunking
- SummarizaÃ§Ã£o automÃ¡tica
- Routing inteligente

### Ferramentas de ProduÃ§Ã£o

**1. Monitoramento:**
- Logging estruturado
- MÃ©tricas de performance
- Alertas de qualidade

**2. Deployment:**
- ContainerizaÃ§Ã£o (Docker)
- OrquestraÃ§Ã£o (Kubernetes)
- Load balancing

**3. SeguranÃ§a:**
- AutenticaÃ§Ã£o e autorizaÃ§Ã£o
- Rate limiting
- Data privacy

---

## ğŸ“š Recursos de Aprendizado

### DocumentaÃ§Ã£o Oficial
- [LangChain](https://python.langchain.com/)
- [ChromaDB](https://docs.trychroma.com/)
- [Ollama](https://ollama.ai/)

### Papers Importantes
- "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" (Facebook AI)
- "Dense Passage Retrieval for Open-Domain Question Answering" (Facebook AI)
- "FiD: Fusion-in-Decoder for Open-domain Question Answering" (Facebook AI)

### Cursos e Tutoriais
- LangChain Academy
- DeepLearning.AI RAG Course
- Hugging Face NLP Course

---

## ğŸ“ ConclusÃ£o

Este tutorial cobriu:

âœ… **Conceitos fundamentais** de RAG
âœ… **Arquitetura tÃ©cnica** completa
âœ… **ImplementaÃ§Ã£o prÃ¡tica** com cÃ³digo
âœ… **Scripts de anÃ¡lise** e debugging
âœ… **MÃ©tricas de avaliaÃ§Ã£o**
âœ… **Casos de uso** reais
âœ… **OtimizaÃ§Ã£o** e troubleshooting
âœ… **PrÃ³ximos passos** para expansÃ£o

**PrÃ³ximas aÃ§Ãµes recomendadas:**
1. Execute todos os scripts bÃ¡sicos
2. Teste com seus prÃ³prios documentos
3. Implemente os scripts avanÃ§ados
4. Experimente diferentes configuraÃ§Ãµes
5. Desenvolva sua prÃ³pria aplicaÃ§Ã£o

**Lembre-se:** RAG Ã© uma tÃ©cnica poderosa que combina o melhor de dois mundos - a precisÃ£o da busca e a fluÃªncia da geraÃ§Ã£o. Com os conhecimentos deste tutorial, vocÃª tem tudo que precisa para construir sistemas RAG robustos e eficazes! ğŸš€
