# üõ°Ô∏è Guia Completo de Guardrails para Sistemas RAG

> **Documenta√ß√£o t√©cnica avan√ßada sobre implementa√ß√£o de guardrails**  
> **Para sistemas RAG seguros, confi√°veis e livres de alucina√ß√µes**

---

## üìö **√çNDICE**

1. **[Introdu√ß√£o aos Guardrails](#introdu√ß√£o-aos-guardrails)**
2. **[Arquitetura de 4 Camadas](#arquitetura-de-4-camadas)**
3. **[Implementa√ß√£o T√©cnica](#implementa√ß√£o-t√©cnica)**
4. **[Configura√ß√£o de Thresholds](#configura√ß√£o-de-thresholds)**
5. **[Templates de Prompt](#templates-de-prompt)**
6. **[M√©tricas e Monitoramento](#m√©tricas-e-monitoramento)**
7. **[Casos de Uso Avan√ßados](#casos-de-uso-avan√ßados)**
8. **[Troubleshooting](#troubleshooting)**

---

## üéØ **Introdu√ß√£o aos Guardrails**

### **Defini√ß√£o**
Guardrails s√£o **sistemas de controle e valida√ß√£o** que garantem que sistemas RAG produzam respostas:
- **Factualmente corretas** (baseadas no contexto)
- **Seguras** (sem conte√∫do malicioso)
- **Confi√°veis** (sem alucina√ß√µes)
- **Rastre√°veis** (com cita√ß√£o de fontes)

### **Por que s√£o Essenciais?**

**Problemas Sem Guardrails:**
```
‚ùå Query: "Qual o CEO da empresa?"
‚ùå Resposta: "O CEO atual √© John Smith, assumiu em 2023..."
‚ùå Problema: Informa√ß√£o INVENTADA - n√£o est√° nos documentos
```

**Com Guardrails:**
```
‚úÖ Query: "Qual o CEO da empresa?"
‚úÖ Resposta: "‚ùå N√£o encontrei informa√ß√µes sobre CEO no contexto dispon√≠vel."
‚úÖ Resultado: HONESTIDADE - sistema admite limita√ß√µes
```

### **Tipos de Falhas que Guardrails Previnem**

1. **Alucina√ß√µes Factuais**
   - LLM inventa fatos n√£o presentes no contexto
   - Dados num√©ricos incorretos
   - Nomes, datas, locais inventados

2. **Extrapola√ß√£o Inadequada**
   - LLM faz infer√™ncias al√©m do contexto
   - Conclus√µes n√£o suportadas pelos dados
   - Generaliza√ß√µes excessivas

3. **Ataques de Injection**
   - Tentativas de manipular o prompt
   - Bypass de instru√ß√µes de sistema
   - Extra√ß√£o de informa√ß√µes sens√≠veis

4. **Respostas Inconsistentes**
   - Varia√ß√£o entre execu√ß√µes
   - Contradi√ß√µes internas
   - Falta de reprodutibilidade

---

## üèóÔ∏è **Arquitetura de 4 Camadas**

### **Fluxo Completo com Guardrails**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   INPUT QUERY   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ üîç INPUT GUARDS ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  VALIDATED QUERY ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FILTERED CHUNKS ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ‚öñÔ∏è RETRIEVAL     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   VECTOR SEARCH  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ   GUARDS        ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LLM RESPONSE   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇüìù PROMPT GUARDS ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ  CONTEXT PREP   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FINAL RESPONSE  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ‚úÖ OUTPUT GUARDS ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ  RAW RESPONSE   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **1. INPUT GUARDRAILS (Primeira Linha de Defesa)**

**Valida√ß√µes Implementadas:**
```python
def validate_input(query: str) -> Tuple[bool, str, str]:
    # Valida√ß√£o b√°sica
    if len(query.strip()) < 3:
        return False, "", "Query muito curta"
    
    # Detec√ß√£o de injection
    injection_patterns = [
        "ignore previous instructions",
        "forget everything", 
        "act as",
        "system:",
        "pretend to be"
    ]
    
    query_lower = query.lower()
    for pattern in injection_patterns:
        if pattern in query_lower:
            return False, query, f"Injection detectada: {pattern}"
    
    return True, query.strip(), ""
```

**Casos Bloqueados:**
- Queries vazias ou muito curtas
- Tentativas de prompt injection
- Caracteres especiais maliciosos
- Comandos de sistema embebidos

### **2. RETRIEVAL GUARDRAILS (Controle de Relev√¢ncia)**

**Threshold de Similaridade:**
```python
def filter_by_threshold(results: List[Tuple[Document, float]], 
                       threshold: float) -> List[Document]:
    """
    Filtra chunks por similaridade usando threshold rigoroso.
    
    ChromaDB retorna dist√¢ncia (menor = mais similar):
    - Score 0.15 = muito similar (ACEITAR)
    - Score 0.45 = pouco similar (REJEITAR se threshold=0.35)
    """
    filtered = []
    for doc, score in results:
        if score <= threshold:  # Menor dist√¢ncia = mais similar
            if validate_chunk_quality(doc):
                filtered.append(doc)
                log_acceptance(doc, score)
            else:
                log_quality_rejection(doc, score)
        else:
            log_threshold_rejection(doc, score, threshold)
    
    return filtered
```

**Valida√ß√£o de Qualidade de Chunks:**
```python
def validate_chunk_quality(doc: Document) -> bool:
    content = doc.page_content.strip()
    
    # Muito pequeno
    if len(content) < 50:
        return False
    
    # Apenas pontua√ß√£o/n√∫meros
    alpha_ratio = sum(c.isalpha() for c in content) / len(content)
    if alpha_ratio < 0.5:
        return False
    
    # Texto repetitivo (heur√≠stica)
    words = content.split()
    if len(set(words)) / len(words) < 0.3:  # Muita repeti√ß√£o
        return False
    
    return True
```

**Estrat√©gias de Threshold:**
```python
# Configura√ß√µes por tipo de sistema
THRESHOLD_CONFIGS = {
    "critical": 0.20,      # Sistema cr√≠tico (medicina, finan√ßas)
    "technical": 0.30,     # Documenta√ß√£o t√©cnica
    "support": 0.40,       # FAQ/Suporte
    "exploratory": 0.50    # Busca explorat√≥ria
}
```

### **3. PROMPT GUARDRAILS (Controle de Comportamento)**

**Template Rigoroso (STRICT):**
```python
STRICT_TEMPLATE = """
Voc√™ √© um assistente que responde EXCLUSIVAMENTE com base no contexto fornecido.

REGRAS OBRIGAT√ìRIAS (N√ÉO QUEBRE NUNCA):
1. Use APENAS informa√ß√µes presentes no CONTEXTO abaixo
2. Se a resposta n√£o estiver no contexto, responda EXATAMENTE: 
   "‚ùå N√£o encontrei informa√ß√µes relevantes no contexto dispon√≠vel."
3. NUNCA invente, deduza, extrapole ou use conhecimento externo
4. SEMPRE cite a fonte: (Fonte: nome_do_arquivo)
5. Responda em portugu√™s brasileiro, seja objetivo e direto

FORMATO OBRIGAT√ìRIO:
‚úÖ Com base no contexto fornecido: [SUA_RESPOSTA_AQUI]
(Fonte: nome_do_arquivo)

CONTEXTO:
{context}

PERGUNTA: {question}

RESPOSTA:
"""
```

**Template Balanceado (BALANCED):**
```python
BALANCED_TEMPLATE = """
Voc√™ √© um assistente especializado que prioriza informa√ß√µes do contexto fornecido.

DIRETRIZES:
1. PRIORIZE SEMPRE as informa√ß√µes do CONTEXTO
2. Use conhecimento geral APENAS para esclarecimentos b√°sicos
3. INDIQUE CLARAMENTE a origem das informa√ß√µes:
   - "Com base no contexto:" para info do contexto
   - "Informa√ß√£o complementar:" para conhecimento geral
4. Se n√£o houver contexto suficiente, seja transparente
5. Sempre cite fontes quando dispon√≠veis

CONTEXTO:
{context}

PERGUNTA: {question}

RESPOSTA:
"""
```

**T√©cnicas Avan√ßadas de Prompt:**
```python
def build_context_aware_prompt(context: str, question: str, 
                              context_confidence: float) -> str:
    """Adapta template baseado na confian√ßa do contexto."""
    
    if context_confidence < 0.3:
        # Contexto de baixa qualidade - template muito rigoroso
        return STRICT_TEMPLATE.format(context=context, question=question)
    
    elif context_confidence > 0.8:
        # Contexto de alta qualidade - template mais flex√≠vel
        return BALANCED_TEMPLATE.format(context=context, question=question)
    
    else:
        # Contexto m√©dio - template padr√£o com avisos
        enhanced_template = STRICT_TEMPLATE.replace(
            "Com base no contexto fornecido:",
            "‚ö†Ô∏è Com base no contexto de qualidade m√©dia fornecido:"
        )
        return enhanced_template.format(context=context, question=question)
```

### **4. OUTPUT GUARDRAILS (Valida√ß√£o Final)**

**Valida√ß√£o de Fidelidade:**
```python
def validate_response_fidelity(response: str, context: str, 
                              threshold: float = 0.3) -> Tuple[bool, float]:
    """
    Valida se resposta est√° fiel ao contexto usando overlap de palavras.
    """
    # Tokeniza√ß√£o e limpeza
    context_words = set(re.findall(r'\w+', context.lower()))
    response_words = set(re.findall(r'\w+', response.lower()))
    
    # Remover stopwords
    stopwords = {'o', 'a', 'de', 'da', 'do', 'para', 'com', 'em', 'que', '√©'}
    context_words -= stopwords
    response_words -= stopwords
    
    # Calcular overlap
    if len(response_words) == 0:
        return False, 0.0
    
    overlap = len(context_words.intersection(response_words))
    fidelity_score = overlap / len(response_words)
    
    return fidelity_score >= threshold, fidelity_score
```

**Detec√ß√£o de Alucina√ß√£o:**
```python
def detect_hallucination(response: str, context: str, 
                        question: str) -> Dict[str, Any]:
    """Detecta poss√≠veis alucina√ß√µes na resposta."""
    
    detection_result = {
        "has_hallucination": False,
        "confidence": 0.0,
        "reasons": []
    }
    
    # 1. Verifica informa√ß√µes num√©ricas espec√≠ficas
    response_numbers = re.findall(r'\d+', response)
    context_numbers = re.findall(r'\d+', context)
    
    for num in response_numbers:
        if num not in context_numbers:
            detection_result["reasons"].append(f"N√∫mero {num} n√£o encontrado no contexto")
            detection_result["has_hallucination"] = True
    
    # 2. Verifica nomes pr√≥prios
    response_proper_nouns = re.findall(r'\b[A-Z][a-z]+\b', response)
    context_proper_nouns = re.findall(r'\b[A-Z][a-z]+\b', context)
    
    for noun in response_proper_nouns:
        if noun not in context_proper_nouns and noun not in question:
            detection_result["reasons"].append(f"Nome pr√≥prio {noun} n√£o no contexto")
            detection_result["has_hallucination"] = True
    
    # 3. Verifica cita√ß√£o de fonte
    has_source_citation = any(pattern in response.lower() for pattern in 
                             ["fonte:", "(fonte", "baseado no contexto"])
    
    if not has_source_citation and "‚ùå N√£o encontrei" not in response:
        detection_result["reasons"].append("Falta cita√ß√£o de fonte")
        detection_result["has_hallucination"] = True
    
    # 4. Calcula confian√ßa final
    if detection_result["has_hallucination"]:
        detection_result["confidence"] = min(1.0, len(detection_result["reasons"]) * 0.3)
    
    return detection_result
```

---

## ‚öôÔ∏è **Configura√ß√£o de Thresholds**

### **Metodologia de Otimiza√ß√£o**

**1. An√°lise Estat√≠stica Base:**
```python
def analyze_similarity_distribution(vectorstore, test_queries):
    """Analisa distribui√ß√£o de scores para encontrar thresholds naturais."""
    all_scores = []
    
    for query in test_queries:
        results = vectorstore.similarity_search_with_score(query, k=20)
        scores = [score for _, score in results]
        all_scores.extend(scores)
    
    stats = {
        "mean": np.mean(all_scores),
        "std": np.std(all_scores),
        "median": np.median(all_scores),
        "q1": np.percentile(all_scores, 25),
        "q3": np.percentile(all_scores, 75),
        "p90": np.percentile(all_scores, 90),
        "p95": np.percentile(all_scores, 95)
    }
    
    return stats, all_scores
```

**2. Sugest√µes Autom√°ticas:**
```python
def suggest_thresholds(stats):
    """Sugere thresholds baseado em an√°lise estat√≠stica."""
    return {
        "conservative": stats["mean"] - 2 * stats["std"],    # Top 2-5%
        "strict": stats["q1"],                               # Top 25%
        "balanced": stats["median"],                         # Top 50%
        "permissive": stats["q3"],                          # Top 75%
        "exploratory": stats["p90"]                         # Top 90%
    }
```

**3. Teste Emp√≠rico:**
```python
def evaluate_threshold_performance(thresholds, test_queries, golden_answers=None):
    """Testa performance de diferentes thresholds."""
    results = {}
    
    for threshold in thresholds:
        metrics = {
            "acceptance_rate": 0,
            "avg_chunks_used": 0,
            "processing_time": 0,
            "quality_score": 0  # Se tiver golden answers
        }
        
        for query in test_queries:
            start_time = time.time()
            
            # Executar RAG com threshold
            response = rag_with_threshold(query, threshold)
            
            metrics["processing_time"] += time.time() - start_time
            
            if response["status"] == "success":
                metrics["acceptance_rate"] += 1
                metrics["avg_chunks_used"] += len(response["chunks_used"])
                
                # Avaliar qualidade se tiver resposta de refer√™ncia
                if golden_answers and query in golden_answers:
                    quality = calculate_quality(response["answer"], golden_answers[query])
                    metrics["quality_score"] += quality
        
        # Normalizar m√©tricas
        metrics["acceptance_rate"] /= len(test_queries)
        metrics["avg_chunks_used"] /= len(test_queries)
        metrics["processing_time"] /= len(test_queries)
        metrics["quality_score"] /= len(test_queries)
        
        results[threshold] = metrics
    
    return results
```

### **Configura√ß√£o por Dom√≠nio**

**Documenta√ß√£o T√©cnica (nosso caso):**
```python
TECHNICAL_CONFIG = {
    "similarity_threshold": 0.30,
    "min_chunks_required": 1,
    "max_chunks_to_llm": 4,
    "template_mode": "strict",
    "require_source_citation": True,
    "fidelity_threshold": 0.4
}
```

**Sistema Cr√≠tico (medicina, finan√ßas):**
```python
CRITICAL_CONFIG = {
    "similarity_threshold": 0.20,
    "min_chunks_required": 2,
    "max_chunks_to_llm": 3,
    "template_mode": "strict",
    "require_source_citation": True,
    "fidelity_threshold": 0.6,
    "enable_human_review": True
}
```

**FAQ/Suporte:**
```python
SUPPORT_CONFIG = {
    "similarity_threshold": 0.45,
    "min_chunks_required": 1,
    "max_chunks_to_llm": 6,
    "template_mode": "balanced",
    "require_source_citation": False,
    "fidelity_threshold": 0.3
}
```

---

## üìä **M√©tricas e Monitoramento**

### **M√©tricas de Guardrails**

**1. M√©tricas de Input:**
```python
input_metrics = {
    "total_queries": 1000,
    "valid_queries": 950,
    "rejected_injection": 30,
    "rejected_format": 20,
    "validation_rate": 0.95
}
```

**2. M√©tricas de Retrieval:**
```python
retrieval_metrics = {
    "avg_chunks_retrieved": 8.5,
    "avg_chunks_accepted": 3.2,
    "acceptance_rate": 0.376,  # 37.6% dos chunks passam no threshold
    "avg_similarity_score": 0.34,
    "queries_with_no_context": 45,  # 4.5% das queries
    "no_context_rate": 0.045
}
```

**3. M√©tricas de Generation:**
```python
generation_metrics = {
    "responses_generated": 905,  # queries que chegaram √† gera√ß√£o
    "avg_response_length": 156,
    "avg_generation_time": 2.3,  # segundos
    "template_strict_usage": 0.7,
    "template_balanced_usage": 0.3
}
```

**4. M√©tricas de Output:**
```python
output_metrics = {
    "responses_validated": 905,
    "responses_with_source": 890,  # 98.3%
    "avg_fidelity_score": 0.67,
    "hallucination_detected": 15,  # 1.7%
    "hallucination_rate": 0.017,
    "final_success_rate": 0.882
}
```

### **Dashboard de Monitoramento**

**Visualiza√ß√£o em Tempo Real:**
```python
def create_guardrails_dashboard():
    """Cria dashboard de monitoramento de guardrails."""
    
    metrics = collect_realtime_metrics()
    
    dashboard = {
        "overview": {
            "total_queries_today": metrics["input"]["total_queries"],
            "success_rate": metrics["output"]["final_success_rate"],
            "avg_response_time": metrics["generation"]["avg_generation_time"],
            "current_threshold": get_current_threshold()
        },
        
        "quality_gates": {
            "input_validation": metrics["input"]["validation_rate"],
            "context_filtering": metrics["retrieval"]["acceptance_rate"],
            "fidelity_check": metrics["output"]["avg_fidelity_score"],
            "hallucination_rate": metrics["output"]["hallucination_rate"]
        },
        
        "performance": {
            "queries_per_minute": calculate_qpm(),
            "p95_response_time": calculate_p95_latency(),
            "error_rate": calculate_error_rate(),
            "memory_usage": get_memory_usage()
        },
        
        "alerts": generate_alerts(metrics)
    }
    
    return dashboard
```

**Alertas Autom√°ticos:**
```python
def generate_alerts(metrics):
    """Gera alertas baseado em thresholds de qualidade."""
    alerts = []
    
    # Taxa de sucesso muito baixa
    if metrics["output"]["final_success_rate"] < 0.8:
        alerts.append({
            "severity": "high",
            "message": f"Taxa de sucesso baixa: {metrics['output']['final_success_rate']:.1%}",
            "action": "Revisar threshold de similaridade"
        })
    
    # Muita rejei√ß√£o de contexto
    if metrics["retrieval"]["no_context_rate"] > 0.1:
        alerts.append({
            "severity": "medium", 
            "message": f"Alta taxa sem contexto: {metrics['retrieval']['no_context_rate']:.1%}",
            "action": "Considerar threshold mais permissivo"
        })
    
    # Detec√ß√£o de alucina√ß√µes frequente
    if metrics["output"]["hallucination_rate"] > 0.05:
        alerts.append({
            "severity": "high",
            "message": f"Taxa de alucina√ß√£o alta: {metrics['output']['hallucination_rate']:.1%}",
            "action": "Revisar template de prompt e threshold"
        })
    
    return alerts
```

---

## üéõÔ∏è **Casos de Uso Avan√ßados**

### **1. Threshold Adaptativo**

**Threshold Baseado na Complexidade da Query:**
```python
def adaptive_threshold(query: str, base_threshold: float = 0.35) -> float:
    """Ajusta threshold baseado na complexidade da query."""
    
    # An√°lise da query
    word_count = len(query.split())
    has_technical_terms = any(term in query.lower() for term in 
                             ['api', 'sistema', 'arquitetura', 'performance'])
    is_specific = any(char in query for char in '?')
    
    # Ajustes
    threshold = base_threshold
    
    # Queries complexas precisam de mais contexto
    if word_count > 8:
        threshold += 0.1
    
    # Queries t√©cnicas podem ser mais rigorosas
    if has_technical_terms:
        threshold -= 0.05
    
    # Perguntas espec√≠ficas podem ser mais rigorosas
    if is_specific:
        threshold -= 0.05
    
    return max(0.15, min(0.6, threshold))  # Limitar entre 0.15 e 0.6
```

**Threshold Baseado no Hist√≥rico:**
```python
def historical_threshold(user_id: str, base_threshold: float) -> float:
    """Ajusta threshold baseado no hist√≥rico de satisfa√ß√£o do usu√°rio."""
    
    user_history = get_user_history(user_id)
    
    if not user_history:
        return base_threshold
    
    # Calcular satisfa√ß√£o m√©dia
    avg_satisfaction = np.mean([h["satisfaction"] for h in user_history])
    
    # Ajustar threshold baseado na satisfa√ß√£o
    if avg_satisfaction < 3.0:  # Usu√°rio insatisfeito
        return base_threshold - 0.1  # Ser mais rigoroso
    elif avg_satisfaction > 4.0:  # Usu√°rio satisfeito
        return base_threshold + 0.05  # Ser mais permissivo
    
    return base_threshold
```

### **2. Valida√ß√£o Sem√¢ntica Avan√ßada**

**Detec√ß√£o de Inconsist√™ncia Sem√¢ntica:**
```python
def semantic_consistency_check(response: str, context: str, 
                              embeddings_model) -> float:
    """Verifica consist√™ncia sem√¢ntica entre resposta e contexto."""
    
    # Gerar embeddings
    response_embedding = embeddings_model.embed_query(response)
    context_embedding = embeddings_model.embed_query(context)
    
    # Calcular similaridade
    similarity = cosine_similarity([response_embedding], [context_embedding])[0][0]
    
    return similarity
```

**Detec√ß√£o de Contradi√ß√µes:**
```python
def detect_contradictions(response: str, context: str) -> List[str]:
    """Detecta contradi√ß√µes entre resposta e contexto."""
    contradictions = []
    
    # Extrair declara√ß√µes num√©ricas
    response_numbers = extract_numeric_statements(response)
    context_numbers = extract_numeric_statements(context)
    
    for resp_stmt in response_numbers:
        for ctx_stmt in context_numbers:
            if are_contradictory(resp_stmt, ctx_stmt):
                contradictions.append(f"Contradi√ß√£o: '{resp_stmt}' vs '{ctx_stmt}'")
    
    return contradictions

def extract_numeric_statements(text: str) -> List[str]:
    """Extrai declara√ß√µes que cont√™m n√∫meros."""
    sentences = sent_tokenize(text)
    numeric_sentences = []
    
    for sentence in sentences:
        if re.search(r'\d+', sentence):
            numeric_sentences.append(sentence.strip())
    
    return numeric_sentences
```

### **3. Guardrails Espec√≠ficos por Dom√≠nio**

**Valida√ß√£o para Documenta√ß√£o T√©cnica:**
```python
def technical_domain_validation(response: str, query: str) -> Dict[str, Any]:
    """Valida√ß√µes espec√≠ficas para documenta√ß√£o t√©cnica."""
    
    validation = {
        "valid": True,
        "warnings": [],
        "errors": []
    }
    
    # 1. Verificar se m√©tricas t√™m unidades
    metrics_pattern = r'(\d+(?:\.\d+)?)\s*(ms|segundos?|GB|MB|%|usu√°rios?)'
    metrics_without_units = re.findall(r'\d+(?:\.\d+)?(?!\s*(?:ms|segundos?|GB|MB|%|usu√°rios?))', response)
    
    if "performance" in query.lower() and metrics_without_units:
        validation["warnings"].append("M√©tricas sem unidades detectadas")
    
    # 2. Verificar consist√™ncia de tecnologias mencionadas
    known_technologies = {
        'spring boot', 'docker', 'kubernetes', 'postgresql', 'redis',
        'prometheus', 'grafana', 'jenkins', 'elasticsearch'
    }
    
    mentioned_techs = set()
    for tech in known_technologies:
        if tech in response.lower():
            mentioned_techs.add(tech)
    
    # Verificar se tecnologias mencionadas fazem sentido juntas
    incompatible_combinations = [
        ({'mysql', 'postgresql'}, "Men√ß√£o de m√∫ltiplos SGBDs"),
        ({'docker', 'kubernetes'}, None)  # Essa √© compat√≠vel
    ]
    
    for incompatible_set, message in incompatible_combinations:
        if message and incompatible_set.issubset(mentioned_techs):
            validation["warnings"].append(message)
    
    return validation
```

**Valida√ß√£o para Sistema de Suporte:**
```python
def support_domain_validation(response: str, query: str) -> Dict[str, Any]:
    """Valida√ß√µes espec√≠ficas para sistema de suporte."""
    
    validation = {
        "valid": True,
        "suggestions": []
    }
    
    # 1. Verificar se resposta tem tom adequado para suporte
    if any(word in response.lower() for word in ['imposs√≠vel', 'n√£o pode', 'nunca']):
        validation["suggestions"].append("Considere tom mais positivo para suporte")
    
    # 2. Verificar se oferece pr√≥ximos passos
    if '?' in query and not any(phrase in response.lower() for phrase in 
                               ['voc√™ pode', 'tente', 'pr√≥ximo passo', 'contacte']):
        validation["suggestions"].append("Considere incluir pr√≥ximos passos")
    
    # 3. Verificar se resposta √© suficientemente detalhada
    if len(response.split()) < 10:
        validation["suggestions"].append("Resposta pode estar muito curta")
    
    return validation
```

---

## üîß **Troubleshooting**

### **Problemas Comuns e Solu√ß√µes**

**1. Alta Taxa de Rejei√ß√£o (>20%)**
```
Sintoma: Muitas queries resultam em "N√£o encontrei informa√ß√µes relevantes"
Causa: Threshold muito rigoroso
Solu√ß√£o:
- Executar threshold_optimizer.py para encontrar valor ideal
- Aumentar threshold gradualmente (ex: 0.30 ‚Üí 0.35 ‚Üí 0.40)
- Verificar qualidade dos embeddings
- Considerar re-indexa√ß√£o com chunks diferentes
```

**2. Respostas com Baixa Fidelidade**
```
Sintoma: Fidelity score < 0.4 consistentemente
Causa: Template muito permissivo ou threshold muito alto
Solu√ß√£o:
- Usar template strict em vez de balanced
- Diminuir threshold de similaridade
- Revisar instru√ß√µes do prompt
- Implementar valida√ß√£o sem√¢ntica adicional
```

**3. Tempo de Resposta Alto**
```
Sintoma: Tempo m√©dio > 5 segundos
Causa: Muitos chunks sendo processados ou valida√ß√µes complexas
Solu√ß√£o:
- Reduzir max_chunks_to_llm
- Implementar cache de embeddings
- Otimizar valida√ß√µes de output
- Usar modelo de embedding menor
```

**4. Detec√ß√£o Excessiva de Alucina√ß√µes**
```
Sintoma: >10% de respostas marcadas como alucina√ß√£o
Causa: Valida√ß√£o muito sens√≠vel ou dados inconsistentes
Solu√ß√£o:
- Ajustar thresholds de detec√ß√£o
- Revisar qualidade dos dados originais
- Melhorar algoritmo de detec√ß√£o
- Validar manualmente casos flagados
```

### **Debugging Avan√ßado**

**1. An√°lise de Decis√µes de Guardrail:**
```python
def analyze_guardrail_decisions(log_file: str):
    """Analisa logs para identificar padr√µes nas decis√µes."""
    
    with open(log_file, 'r') as f:
        logs = f.readlines()
    
    decisions = {
        "input_rejected": [],
        "threshold_rejected": [],
        "quality_rejected": [],
        "hallucination_detected": []
    }
    
    for line in logs:
        if "input_rejected" in line:
            decisions["input_rejected"].append(parse_log_line(line))
        elif "threshold_rejected" in line:
            decisions["threshold_rejected"].append(parse_log_line(line))
        # ... etc
    
    # An√°lise de padr√µes
    patterns = {
        "most_rejected_query_types": analyze_query_patterns(decisions["threshold_rejected"]),
        "common_hallucination_triggers": analyze_hallucination_patterns(decisions["hallucination_detected"]),
        "threshold_effectiveness": calculate_threshold_effectiveness(decisions)
    }
    
    return patterns
```

**2. Teste A/B de Configura√ß√µes:**
```python
def ab_test_guardrail_configs(config_a: dict, config_b: dict, 
                             test_queries: List[str]) -> Dict[str, Any]:
    """Testa duas configura√ß√µes de guardrail para comparar performance."""
    
    results = {"config_a": {}, "config_b": {}}
    
    for config_name, config in [("config_a", config_a), ("config_b", config_b)]:
        rag_system = RAGWithGuardrails(**config)
        
        metrics = {
            "success_rate": 0,
            "avg_fidelity": 0,
            "avg_response_time": 0,
            "hallucination_rate": 0
        }
        
        for query in test_queries:
            start_time = time.time()
            result = rag_system.query_with_guardrails(query)
            end_time = time.time()
            
            metrics["avg_response_time"] += (end_time - start_time)
            
            if result["status"] == "success":
                metrics["success_rate"] += 1
                metrics["avg_fidelity"] += result.get("fidelity_score", 0)
                
                if result.get("hallucination_detected", False):
                    metrics["hallucination_rate"] += 1
        
        # Normalizar
        total_queries = len(test_queries)
        metrics["success_rate"] /= total_queries
        metrics["avg_fidelity"] /= total_queries
        metrics["avg_response_time"] /= total_queries
        metrics["hallucination_rate"] /= total_queries
        
        results[config_name] = metrics
    
    # Compara√ß√£o estat√≠stica
    comparison = compare_configs(results["config_a"], results["config_b"])
    results["statistical_significance"] = comparison
    
    return results
```

---

## üöÄ **Pr√≥ximos Passos**

### **Implementa√ß√µes Futuras**

**1. Guardrails com Machine Learning:**
```python
# Modelo treinado para detectar alucina√ß√µes
class HallucinationDetector:
    def __init__(self):
        self.model = load_pretrained_model("hallucination_detector.pkl")
    
    def predict(self, response: str, context: str) -> float:
        features = extract_features(response, context)
        return self.model.predict_proba([features])[0][1]  # Probabilidade de alucina√ß√£o
```

**2. Guardrails Adaptativos:**
```python
# Sistema que aprende e ajusta thresholds automaticamente
class AdaptiveGuardrails:
    def __init__(self):
        self.feedback_history = []
        self.current_threshold = 0.35
    
    def update_threshold(self, user_feedback: float):
        """Ajusta threshold baseado no feedback do usu√°rio."""
        self.feedback_history.append(user_feedback)
        
        if len(self.feedback_history) >= 10:
            avg_satisfaction = np.mean(self.feedback_history[-10:])
            
            if avg_satisfaction < 3.0:
                self.current_threshold -= 0.02  # Ser mais rigoroso
            elif avg_satisfaction > 4.0:
                self.current_threshold += 0.02  # Ser mais permissivo
```

**3. Integra√ß√£o com Ferramentas Externas:**
```python
# Integra√ß√£o com Guardrails AI
from guardrails import Guard
from guardrails.validators import ValidLength, RegexMatch

guard = Guard.from_rail_string("""
<rail version="0.1">
<output>
    <string name="response" 
            validators="valid-length: 10 500, regex-match: ^‚úÖ.*"
            on-fail="exception"/>
</output>
</rail>
""")

# Uso integrado
validated_response = guard(llm_function)(prompt)
```

### **Roadmap de Melhorias**

1. **Curto Prazo (1-2 semanas):**
   - Implementar threshold adaptativo por tipo de query
   - Adicionar mais valida√ß√µes de dom√≠nio espec√≠fico
   - Melhorar algoritmos de detec√ß√£o de alucina√ß√£o

2. **M√©dio Prazo (1-2 meses):**
   - Treinar modelo ML para detec√ß√£o de alucina√ß√µes
   - Implementar A/B testing autom√°tico de configura√ß√µes
   - Desenvolver dashboard de monitoramento avan√ßado

3. **Longo Prazo (3+ meses):**
   - Integra√ß√£o com ferramentas externas (Guardrails AI, NeMo)
   - Sistema de feedback loop autom√°tico
   - Guardrails espec√≠ficos por usu√°rio/contexto

---

**Os Guardrails s√£o a diferen√ßa entre um prot√≥tipo interessante e um sistema confi√°vel para produ√ß√£o!** üõ°Ô∏è

Implemente gradualmente, monitore constantemente, e ajuste baseado em dados reais. A seguran√ßa e qualidade do seu sistema RAG dependem dessas prote√ß√µes.
