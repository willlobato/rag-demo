# RAG Demo - RecuperaÃ§Ã£o e GeraÃ§Ã£o Aumentada com Ollama

Um projeto de demonstraÃ§Ã£o de RAG (Retrieval-Augmented Generation) usando Ollama para modelos locais, ChromaDB para armazenamento vetorial e LangChain para orquestraÃ§Ã£o.

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um sistema RAG completo que:

- **Processa documentos** (TXT, MD, PDF) e os divide em chunks
- **Gera embeddings** usando o modelo `nomic-embed-text` do Ollama
- **Armazena vetores** no ChromaDB com persistÃªncia automÃ¡tica
- **Responde perguntas** usando o modelo `llama3` com contexto recuperado

## ğŸ› ï¸ PrÃ©-requisitos

### 1. Ollama

Instale o Ollama e baixe os modelos necessÃ¡rios:

```bash
# Instalar Ollama (macOS)
brew install ollama

# Iniciar o serviÃ§o
brew services start ollama

# Baixar os modelos
ollama pull llama3
ollama pull nomic-embed-text
```

### 2. Python 3.8+

Certifique-se de ter Python 3.8 ou superior instalado.

## ğŸš€ InstalaÃ§Ã£o

1. **Clone ou baixe o projeto**

2. **Instale as dependÃªncias:**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“ Estrutura do Projeto

```
rag-demo/
â”œâ”€â”€ rag_demo/              # Pacote principal
â”‚   â”œâ”€â”€ __init__.py        # InicializaÃ§Ã£o do pacote
â”‚   â”œâ”€â”€ config.py          # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ ingest.py          # LÃ³gica de ingestÃ£o de documentos
â”‚   â”œâ”€â”€ rag.py             # Sistema RAG principal
â”‚   â””â”€â”€ utils.py           # FunÃ§Ãµes utilitÃ¡rias
â”œâ”€â”€ scripts/               # Scripts executÃ¡veis
â”‚   â”œâ”€â”€ run_ingest.py      # Script para ingestÃ£o
â”‚   â”œâ”€â”€ run_query.py       # Script para consultas RAG
â”‚   â”œâ”€â”€ list_docs.py       # Script para listar documentos
â”‚   â””â”€â”€ search_docs.py     # Script para busca semÃ¢ntica
â”œâ”€â”€ requirements.txt       # DependÃªncias Python
â”œâ”€â”€ .gitignore            # Arquivos a ignorar no Git
â”œâ”€â”€ .env.example          # Template de variÃ¡veis de ambiente
â”œâ”€â”€ data/                 # Documentos de entrada
â”‚   â””â”€â”€ guia.txt          # Exemplo de documento
â””â”€â”€ db/                   # Banco vetorial ChromaDB (criado automaticamente)
```

## ğŸ¯ Como Usar

### 1. Indexar Documentos

```bash
# Processar documentos da pasta data/
python scripts/run_ingest.py

# Para resetar o Ã­ndice completamente
RESET_CHROMA=1 python scripts/run_ingest.py
```

O script processa automaticamente:
- Arquivos `.txt` e `.md` da pasta `data/`
- Arquivos `.pdf` da pasta `data/`
- Se nÃ£o houver arquivos, usa documentos de exemplo

### 2. Fazer Consultas RAG

```bash
# Pergunta padrÃ£o
python scripts/run_query.py

# Pergunta customizada
python scripts/run_query.py "Como otimizar o processo de login?"
python scripts/run_query.py "O que Ã© RAG e como funciona?"
```

### 3. Explorar o Ãndice

```bash
# Listar todos os documentos indexados
python scripts/list_docs.py

# Busca semÃ¢ntica direta (sem LLM)
python scripts/search_docs.py "otimizaÃ§Ã£o de login" 3
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Modelos

VocÃª pode alterar os modelos editando as constantes em `rag_demo/config.py`:

```python
# Em rag_demo/config.py
LLM_MODEL = "llama3"          # Modelo para geraÃ§Ã£o de texto
EMB_MODEL = "nomic-embed-text" # Modelo para embeddings
```

### ParÃ¢metros de Chunking

```python
# Em rag_demo/config.py
CHUNK_SIZE = 500      # Tamanho mÃ¡ximo do chunk
CHUNK_OVERLAP = 80    # SobreposiÃ§Ã£o entre chunks
```

### RecuperaÃ§Ã£o

```python
# Em rag_demo/config.py
RETRIEVAL_K = 4  # NÃºmero de chunks recuperados
```

### VariÃ¡veis de Ambiente

Copie `.env.example` para `.env` e ajuste as configuraÃ§Ãµes:

```bash
cp .env.example .env
# Edite o arquivo .env conforme necessÃ¡rio
```

## ğŸ“š Funcionalidades Principais

### `rag_demo/ingest.py`
- Carrega documentos TXT, MD e PDF
- Divide em chunks com sobreposiÃ§Ã£o
- Gera embeddings e salva no ChromaDB
- Suporte para reset do Ã­ndice

### `rag_demo/rag.py`
- Sistema RAG completo
- Recupera contexto relevante
- Gera respostas com modelo Ollama
- Inclui fontes nas respostas

### `rag_demo/config.py`
- ConfiguraÃ§Ãµes centralizadas
- Suporte a variÃ¡veis de ambiente
- ParÃ¢metros configurÃ¡veis

### Scripts ExecutÃ¡veis
- **`scripts/run_ingest.py`**: Executa a ingestÃ£o de documentos
- **`scripts/run_query.py`**: Faz consultas RAG
- **`scripts/list_docs.py`**: Lista documentos indexados
- **`scripts/search_docs.py`**: Busca semÃ¢ntica pura

## ğŸ”§ Troubleshooting

### Ollama nÃ£o estÃ¡ rodando
```bash
# Verificar se estÃ¡ ativo
ollama list

# Iniciar manualmente
ollama serve
```

### Modelos nÃ£o encontrados
```bash
# Baixar modelos necessÃ¡rios
ollama pull llama3
ollama pull nomic-embed-text
```

### Erro de dependÃªncias
```bash
# Reinstalar dependÃªncias
pip install -r requirements.txt --upgrade
```

### ChromaDB corrompido
```bash
# Resetar completamente o Ã­ndice
RESET_CHROMA=1 python scripts/run_ingest.py
```

## ğŸ“„ Exemplo de Uso

```bash
# 1. Indexar documentos
python scripts/run_ingest.py

# 2. Fazer uma pergunta
python scripts/run_query.py "Como foi otimizado o processo de login?"

# SaÃ­da esperada:
# [Q] Como foi otimizado o processo de login?
# 
# O processo de login foi otimizado atravÃ©s de duas principais estratÃ©gias:
# 1. ImplementaÃ§Ã£o de cache distribuÃ­do com Infinispan
# 2. UtilizaÃ§Ã£o de paralelismo nas chamadas de API
# 
# Essas otimizaÃ§Ãµes resultaram numa reduÃ§Ã£o significativa do tempo mÃ©dio
# de login, passando de 4 segundos para 1,2 segundos.
#
# Fontes: data/guia.txt
```

## ğŸ¤ ContribuiÃ§Ã£o

Este Ã© um projeto de demonstraÃ§Ã£o educacional. Sinta-se Ã  vontade para:

- Adicionar novos tipos de documentos
- Melhorar o sistema de prompt
- Implementar interfaces web
- Adicionar mÃ©tricas de avaliaÃ§Ã£o

## ğŸ“ LicenÃ§a

Projeto educacional de cÃ³digo aberto.
